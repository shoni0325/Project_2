{"cells":[{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":469,"status":"ok","timestamp":1690942208577,"user":{"displayName":"유영상","userId":"15974084271948596656"},"user_tz":-540},"id":"YABpMVoh-egK"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split,KFold\n","from sklearn.preprocessing import StandardScaler\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["train=pd.read_csv('../data/train_상장_1대1.csv', encoding='euc-kr')\n","test=pd.read_csv('../data/test_상장_1대1.csv',encoding='euc-kr')"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["X_train_int=train[['부채비율', '총자본회전률', '매출액대비잉여현금흐름', 'PBR', '총자산대비영업현금흐름',\n","       '자기자본증가율', '총자본투자효율', '총자본순이익률', '매출액영업이익률']]\n","\n","X_test_int=test[['부채비율', '총자본회전률', '매출액대비잉여현금흐름', 'PBR', '총자산대비영업현금흐름',\n","       '자기자본증가율', '총자본투자효율', '총자본순이익률', '매출액영업이익률']]"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1690942212262,"user":{"displayName":"유영상","userId":"15974084271948596656"},"user_tz":-540},"id":"FeHi02wm_p4X"},"outputs":[],"source":["X_train = train.drop('t-1감사의견코드',axis=1)\n","y_train = train[['t-1감사의견코드']]\n","\n","X_test = test.drop('t-1감사의견코드',axis=1)\n","y_test = test[['t-1감사의견코드']]"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1690942212263,"user":{"displayName":"유영상","userId":"15974084271948596656"},"user_tz":-540},"id":"Dao53YjZ_sb6"},"outputs":[],"source":["X_train_sc = X_train\n","X_test_sc = X_test"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["X_train_sum =X_train_sc\n","X_test_sum =X_test_sc"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["from sklearn.model_selection import StratifiedKFold, GridSearchCV\n","from xgboost import XGBClassifier\n","import numpy as np\n","\n","def perform_xgb_grid_search(X_train, y_train, k_fold=5):\n","    # Stratified k-fold cross validation setup\n","    cv = StratifiedKFold(n_splits=k_fold, shuffle=True, random_state=0)\n","\n","    # XGBoost hyperparameter candidate list setup\n","    param_grid = {\n","        'max_depth': [3, 5, 7],\n","        'n_estimators': [150, 200, 250],\n","        'learning_rate': [0.01, 0.1, 0.2],\n","        'objective': ['binary:logistic'],\n","        'random_state': [0]\n","    }\n","\n","    # Initialize an XGBoost classifier\n","    model = XGBClassifier(use_label_encoder=False)\n","\n","    # Grid search setup\n","    grid_search = GridSearchCV(model, param_grid, scoring='f1', cv=cv, verbose=1, n_jobs=-1)\n","\n","    # Fit the model and tune\n","    grid_search.fit(X_train, y_train)\n","\n","    # Print the best hyperparameters\n","    print(\"Best Hyperparameters:\", grid_search.best_params_)\n","\n","    # Calculate the average evaluation metric\n","    mean_f1_score = np.mean(grid_search.cv_results_['mean_test_score'])\n","    print(\"Mean F1 Score:\", mean_f1_score)\n","\n","    return grid_search.best_params_, mean_f1_score\n"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["from sklearn.model_selection import StratifiedKFold\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n","from xgboost import XGBClassifier\n","import numpy as np\n","\n","def evaluate_xgb_with_best_params(X_train, y_train, X_test, y_test, best_params, k_fold=5):\n","    # Stratified k-fold cross validation setup\n","    cv = StratifiedKFold(n_splits=k_fold, shuffle=True, random_state=0)\n","\n","    # Initialize an XGBoost model\n","    model = XGBClassifier(**best_params, use_label_encoder=False)\n","\n","    # Lists to save the evaluation metrics for each fold\n","    accuracy_list = []\n","    precision_list = []\n","    recall_list = []\n","    f1_score_list = []\n","    confusion_matrix_list = []\n","\n","    best_f1_score = 0\n","    best_model = None\n","\n","    for fold_idx, (train_idx, test_idx) in enumerate(cv.split(X_train, y_train), 1):\n","        X_train_fold, y_train_fold = X_train.iloc[train_idx], y_train.iloc[train_idx]\n","        X_test_fold, y_test_fold = X_train.iloc[test_idx], y_train.iloc[test_idx]\n","\n","        # Fit the model\n","        model.fit(X_train_fold, y_train_fold)\n","\n","        # Get the predicted probabilities on the test data\n","        probabilities = model.predict_proba(X_test_fold)\n","\n","        # Adjust the predicted classes with a threshold of 0.5\n","        threshold = 0.5\n","        predicted_classes = (probabilities[:, 1] > threshold).astype(np.int)\n","\n","        # Calculate the evaluation metrics\n","        accuracy = accuracy_score(y_test_fold, predicted_classes)\n","        precision = precision_score(y_test_fold, predicted_classes)\n","        recall = recall_score(y_test_fold, predicted_classes)\n","        f1 = f1_score(y_test_fold, predicted_classes)\n","        conf_matrix = confusion_matrix(y_test_fold, predicted_classes)\n","\n","        # Append the evaluation metrics for each fold to the lists\n","        accuracy_list.append(accuracy)\n","        precision_list.append(precision)\n","        recall_list.append(recall)\n","        f1_score_list.append(f1)\n","        confusion_matrix_list.append(conf_matrix)\n","\n","        print(f\"Fold {fold_idx}\")\n","        print(f\"Accuracy: {accuracy}\")\n","        print(f\"Precision: {precision}\")\n","        print(f\"Recall: {recall}\")\n","        print(f\"F1 score: {f1}\")\n","        print(\"Confusion Matrix:\")\n","        print(conf_matrix)\n","        print(\"------------------------------\")\n","\n","        # Save the model with the best F1 score\n","        if f1 > best_f1_score:\n","            best_f1_score = f1\n","            best_model = model\n","\n","    # Perform the final prediction with the model with the best F1 score\n","    probabilities_final = best_model.predict_proba(X_test)\n","    y_pred_final = (probabilities_final[:, 1] > threshold).astype(np.int)\n","\n","    # Calculate the evaluation metrics\n","    accuracy_final = accuracy_score(y_test, y_pred_final)\n","    precision_final = precision_score(y_test, y_pred_final)\n","    recall_final = recall_score(y_test, y_pred_final)\n","    f1_final = f1_score(y_test, y_pred_final)\n","    conf_matrix_final = confusion_matrix(y_test, y_pred_final)\n","\n","    print(\"Final Test Results\")\n","    print(f\"Accuracy: {accuracy_final}\")\n","    print(f\"Precision: {precision_final}\")\n","    print(f\"Recall: {recall_final}\")\n","    print(f\"F1 score: {f1_final}\")\n","    print(\"Confusion Matrix:\")\n","    print(conf_matrix_final)\n","\n","    return accuracy_list, precision_list, recall_list, f1_score_list\n"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 5 folds for each of 27 candidates, totalling 135 fits\n","Best Hyperparameters: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 150, 'objective': 'binary:logistic', 'random_state': 0}\n","Mean F1 Score: 0.8077794881593058\n","Fold 1\n","Accuracy: 0.8055555555555556\n","Precision: 0.7619047619047619\n","Recall: 0.8888888888888888\n","F1 score: 0.8205128205128205\n","Confusion Matrix:\n","[[13  5]\n"," [ 2 16]]\n","------------------------------\n","Fold 2\n","Accuracy: 0.8333333333333334\n","Precision: 0.8\n","Recall: 0.8888888888888888\n","F1 score: 0.8421052631578948\n","Confusion Matrix:\n","[[14  4]\n"," [ 2 16]]\n","------------------------------\n","Fold 3\n","Accuracy: 0.8611111111111112\n","Precision: 0.8421052631578947\n","Recall: 0.8888888888888888\n","F1 score: 0.8648648648648649\n","Confusion Matrix:\n","[[15  3]\n"," [ 2 16]]\n","------------------------------\n","Fold 4\n","Accuracy: 0.75\n","Precision: 0.7368421052631579\n","Recall: 0.7777777777777778\n","F1 score: 0.7567567567567567\n","Confusion Matrix:\n","[[13  5]\n"," [ 4 14]]\n","------------------------------\n","Fold 5\n","Accuracy: 0.8888888888888888\n","Precision: 0.8888888888888888\n","Recall: 0.8888888888888888\n","F1 score: 0.8888888888888888\n","Confusion Matrix:\n","[[16  2]\n"," [ 2 16]]\n","------------------------------\n","Final Test Results\n","Accuracy: 0.7777777777777778\n","Precision: 0.8\n","Recall: 0.7407407407407407\n","F1 score: 0.7692307692307692\n","Confusion Matrix:\n","[[22  5]\n"," [ 7 20]]\n"]},{"data":{"text/plain":["([0.8055555555555556,\n","  0.8333333333333334,\n","  0.8611111111111112,\n","  0.75,\n","  0.8888888888888888],\n"," [0.7619047619047619,\n","  0.8,\n","  0.8421052631578947,\n","  0.7368421052631579,\n","  0.8888888888888888],\n"," [0.8888888888888888,\n","  0.8888888888888888,\n","  0.8888888888888888,\n","  0.7777777777777778,\n","  0.8888888888888888],\n"," [0.8205128205128205,\n","  0.8421052631578948,\n","  0.8648648648648649,\n","  0.7567567567567567,\n","  0.8888888888888888])"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["best_params, mean_f1_score = perform_xgb_grid_search(X_train, y_train, k_fold=5)\n","evaluate_xgb_with_best_params(X_train_int, y_train, X_test_int, y_test, best_params, k_fold=5)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMslPt6t0i1VXXo9sr8JOgH","gpuType":"T4","machine_shape":"hm","mount_file_id":"1530u3ee6bMgQ8qYx2NLdrQsA_-uD-nG6","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":0}
