{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":469,"status":"ok","timestamp":1690942208577,"user":{"displayName":"유영상","userId":"15974084271948596656"},"user_tz":-540},"id":"YABpMVoh-egK"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split,KFold\n","from sklearn.preprocessing import StandardScaler"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":3084,"status":"ok","timestamp":1690942212261,"user":{"displayName":"유영상","userId":"15974084271948596656"},"user_tz":-540},"id":"yultI1-Y-9S8"},"outputs":[],"source":["train=pd.read_csv('../data/Undersampling_0.33_train.csv', encoding='euc-kr')\n","test=pd.read_csv('../data/test_다시.csv',encoding='euc-kr')"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1690942212262,"user":{"displayName":"유영상","userId":"15974084271948596656"},"user_tz":-540},"id":"0DcubbyL_Pli"},"outputs":[],"source":["X_train_int=train[['부채비율', '총자본회전률', '매출액대비잉여현금흐름', 'PBR', '총자산대비영업현금흐름',\n","       '자기자본증가율', '총자본투자효율', '총자본순이익률', '매출액영업이익률']]\n","\n","X_test_int=test[['부채비율', '총자본회전률', '매출액대비잉여현금흐름', 'PBR', '총자산대비영업현금흐름',\n","       '자기자본증가율', '총자본투자효율', '총자본순이익률', '매출액영업이익률']]"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1690942212262,"user":{"displayName":"유영상","userId":"15974084271948596656"},"user_tz":-540},"id":"FeHi02wm_p4X"},"outputs":[],"source":["X_train = train.drop('t-1감사의견코드',axis=1)\n","y_train = train[['t-1감사의견코드']]\n","\n","X_test = test.drop('t-1감사의견코드',axis=1)\n","y_test = test[['t-1감사의견코드']]"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1690942212263,"user":{"displayName":"유영상","userId":"15974084271948596656"},"user_tz":-540},"id":"Dao53YjZ_sb6"},"outputs":[],"source":["X_train_sc = X_train\n","X_test_sc = X_test"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["X_train_sum =X_train_sc\n","X_test_sum =X_test_sc"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["from sklearn.model_selection import StratifiedKFold, GridSearchCV\n","from sklearn.linear_model import LogisticRegression\n","import numpy as np\n","\n","def perform_logit_grid_search(X_train, y_train, k_fold=5):\n","    # Stratified k-fold cross validation setup\n","    cv = StratifiedKFold(n_splits=k_fold, shuffle=True, random_state=0)\n","\n","    # Logistic Regression hyperparameter candidate list setup\n","    param_grid = {\n","        'C': [0.2,0.3,0.4],\n","        'penalty': ['l2'],\n","        'solver': ['liblinear'],\n","        'random_state': [0]\n","    }\n","\n","    # Initialize a Logistic Regression model\n","    model = LogisticRegression()\n","\n","    # Grid search setup\n","    grid_search = GridSearchCV(model, param_grid, scoring='f1', cv=cv, verbose=1, n_jobs=-1)\n","\n","    # Fit the model and tune\n","    grid_search.fit(X_train, y_train)\n","\n","    # Print the best hyperparameters\n","    print(\"Best Hyperparameters:\", grid_search.best_params_)\n","\n","    # Calculate the average evaluation metric\n","    mean_f1_score = np.mean(grid_search.cv_results_['mean_test_score'])\n","    print(\"Mean F1 Score:\", mean_f1_score)\n","\n","    return grid_search.best_params_, mean_f1_score\n"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["from sklearn.model_selection import StratifiedKFold\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n","from sklearn.linear_model import LogisticRegression\n","import numpy as np\n","\n","def evaluate_logit_with_best_params(X_train, y_train, X_test, y_test, best_params, k_fold=5):\n","    # Stratified k-fold cross validation setup\n","    cv = StratifiedKFold(n_splits=k_fold, shuffle=True, random_state=0)\n","\n","    # Initialize a Logistic Regression model\n","    model = LogisticRegression(**best_params)\n","\n","    # Lists to save the evaluation metrics for each fold\n","    accuracy_list = []\n","    precision_list = []\n","    recall_list = []\n","    f1_score_list = []\n","    confusion_matrix_list = []\n","\n","    best_f1_score = 0\n","    best_model = None\n","\n","    for fold_idx, (train_idx, test_idx) in enumerate(cv.split(X_train, y_train), 1):\n","        X_train_fold, y_train_fold = X_train.iloc[train_idx], y_train.iloc[train_idx]\n","        X_test_fold, y_test_fold = X_train.iloc[test_idx], y_train.iloc[test_idx]\n","\n","        # Fit the model\n","        model.fit(X_train_fold, y_train_fold)\n","\n","        # Get the predicted probabilities on the test data\n","        probabilities = model.predict_proba(X_test_fold)\n","\n","        # Adjust the predicted classes with a threshold of 0.5\n","        threshold = 0.5\n","        predicted_classes = (probabilities[:, 1] > threshold).astype(np.int)\n","\n","        # Calculate the evaluation metrics\n","        accuracy = accuracy_score(y_test_fold, predicted_classes)\n","        precision = precision_score(y_test_fold, predicted_classes)\n","        recall = recall_score(y_test_fold, predicted_classes)\n","        f1 = f1_score(y_test_fold, predicted_classes)\n","        conf_matrix = confusion_matrix(y_test_fold, predicted_classes)\n","\n","        # Append the evaluation metrics for each fold to the lists\n","        accuracy_list.append(accuracy)\n","        precision_list.append(precision)\n","        recall_list.append(recall)\n","        f1_score_list.append(f1)\n","        confusion_matrix_list.append(conf_matrix)\n","\n","        print(f\"Fold {fold_idx}\")\n","        print(f\"Accuracy: {accuracy}\")\n","        print(f\"Precision: {precision}\")\n","        print(f\"Recall: {recall}\")\n","        print(f\"F1 score: {f1}\")\n","        print(\"Confusion Matrix:\")\n","        print(conf_matrix)\n","        print(\"------------------------------\")\n","\n","        # Save the model with the best F1 score\n","        if f1 > best_f1_score:\n","            best_f1_score = f1\n","            best_model = model\n","\n","\n","    # Perform the final prediction with the model with the best F1 score\n","    probabilities_final = best_model.predict_proba(X_test)\n","    y_pred_final = (probabilities_final[:, 1] > threshold).astype(np.int)\n","\n","    # Calculate the evaluation metrics\n","    accuracy_final = accuracy_score(y_test, y_pred_final)\n","    precision_final = precision_score(y_test, y_pred_final)\n","    recall_final = recall_score(y_test, y_pred_final)\n","    f1_final = f1_score(y_test, y_pred_final)\n","    conf_matrix_final = confusion_matrix(y_test, y_pred_final)\n","\n","    print(\"Final Test Results\")\n","    print(f\"Accuracy: {accuracy_final}\")\n","    print(f\"Precision: {precision_final}\")\n","    print(f\"Recall: {recall_final}\")\n","    print(f\"F1 score: {f1_final}\")\n","    print(\"Confusion Matrix:\")\n","    print(conf_matrix_final)\n","\n","    return accuracy_list, precision_list, recall_list, f1_score_list\n"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 5 folds for each of 3 candidates, totalling 15 fits\n","Best Hyperparameters: {'C': 0.3, 'penalty': 'l2', 'random_state': 0, 'solver': 'liblinear'}\n","Mean F1 Score: 0.5555906337921211\n","Fold 1\n","Accuracy: 0.8767123287671232\n","Precision: 0.9090909090909091\n","Recall: 0.5555555555555556\n","F1 score: 0.6896551724137931\n","Confusion Matrix:\n","[[54  1]\n"," [ 8 10]]\n","------------------------------\n","Fold 2\n","Accuracy: 0.7808219178082192\n","Precision: 0.5833333333333334\n","Recall: 0.3888888888888889\n","F1 score: 0.4666666666666666\n","Confusion Matrix:\n","[[50  5]\n"," [11  7]]\n","------------------------------\n","Fold 3\n","Accuracy: 0.7916666666666666\n","Precision: 0.6363636363636364\n","Recall: 0.3888888888888889\n","F1 score: 0.4827586206896552\n","Confusion Matrix:\n","[[50  4]\n"," [11  7]]\n","------------------------------\n","Fold 4\n","Accuracy: 0.8611111111111112\n","Precision: 0.8333333333333334\n","Recall: 0.5555555555555556\n","F1 score: 0.6666666666666667\n","Confusion Matrix:\n","[[52  2]\n"," [ 8 10]]\n","------------------------------\n","Fold 5\n","Accuracy: 0.8055555555555556\n","Precision: 0.7\n","Recall: 0.3888888888888889\n","F1 score: 0.5\n","Confusion Matrix:\n","[[51  3]\n"," [11  7]]\n","------------------------------\n","Final Test Results\n","Accuracy: 0.929289170078154\n","Precision: 0.0546448087431694\n","Recall: 0.37037037037037035\n","F1 score: 0.09523809523809523\n","Confusion Matrix:\n","[[2487  173]\n"," [  17   10]]\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\shoni\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","c:\\Users\\shoni\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","C:\\Users\\shoni\\AppData\\Local\\Temp\\ipykernel_17052\\1220324254.py:35: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  predicted_classes = (probabilities[:, 1] > threshold).astype(np.int)\n","c:\\Users\\shoni\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","C:\\Users\\shoni\\AppData\\Local\\Temp\\ipykernel_17052\\1220324254.py:35: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  predicted_classes = (probabilities[:, 1] > threshold).astype(np.int)\n","c:\\Users\\shoni\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","C:\\Users\\shoni\\AppData\\Local\\Temp\\ipykernel_17052\\1220324254.py:35: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  predicted_classes = (probabilities[:, 1] > threshold).astype(np.int)\n","c:\\Users\\shoni\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","C:\\Users\\shoni\\AppData\\Local\\Temp\\ipykernel_17052\\1220324254.py:35: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  predicted_classes = (probabilities[:, 1] > threshold).astype(np.int)\n","c:\\Users\\shoni\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","C:\\Users\\shoni\\AppData\\Local\\Temp\\ipykernel_17052\\1220324254.py:35: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  predicted_classes = (probabilities[:, 1] > threshold).astype(np.int)\n","C:\\Users\\shoni\\AppData\\Local\\Temp\\ipykernel_17052\\1220324254.py:68: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  y_pred_final = (probabilities_final[:, 1] > threshold).astype(np.int)\n"]},{"data":{"text/plain":["([0.8767123287671232,\n","  0.7808219178082192,\n","  0.7916666666666666,\n","  0.8611111111111112,\n","  0.8055555555555556],\n"," [0.9090909090909091,\n","  0.5833333333333334,\n","  0.6363636363636364,\n","  0.8333333333333334,\n","  0.7],\n"," [0.5555555555555556,\n","  0.3888888888888889,\n","  0.3888888888888889,\n","  0.5555555555555556,\n","  0.3888888888888889],\n"," [0.6896551724137931,\n","  0.4666666666666666,\n","  0.4827586206896552,\n","  0.6666666666666667,\n","  0.5])"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["best_params, mean_f1_score = perform_logit_grid_search(X_train, y_train, k_fold=5)\n","evaluate_logit_with_best_params(X_train_int, y_train, X_test_int, y_test, best_params, k_fold=5)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMslPt6t0i1VXXo9sr8JOgH","gpuType":"T4","machine_shape":"hm","mount_file_id":"1530u3ee6bMgQ8qYx2NLdrQsA_-uD-nG6","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":0}
