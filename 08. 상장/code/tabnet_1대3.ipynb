{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "from sklearn.metrics import accuracy_score,f1_score,recall_score,precision_score,confusion_matrix,ConfusionMatrixDisplay,roc_curve,roc_auc_score,precision_recall_curve\n",
    "from sklearn.ensemble import RandomForestClassifier , StackingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "# from lightgbm import LGBMClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression,Lasso\n",
    "from sklearn.preprocessing import Binarizer\n",
    "from sklearn.model_selection import cross_val_score,GridSearchCV\n",
    "\n",
    "# 한글 깨짐 방지\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] = 'malgun Gothic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('../data/train_상장_1대1.csv', encoding='euc-kr')\n",
    "test=pd.read_csv('../data/test_상장_1대1.csv',encoding='euc-kr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_int=train[['부채비율', '총자본회전률', '매출액대비잉여현금흐름', 'PBR', '총자산대비영업현금흐름',\n",
    "       '자기자본증가율', '총자본투자효율', '총자본순이익률', '매출액영업이익률']]\n",
    "\n",
    "X_test_int=test[['부채비율', '총자본회전률', '매출액대비잉여현금흐름', 'PBR', '총자산대비영업현금흐름',\n",
    "       '자기자본증가율', '총자본투자효율', '총자본순이익률', '매출액영업이익률']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop('t-1감사의견코드',axis=1)\n",
    "y_train = train[['t-1감사의견코드']]\n",
    "\n",
    "X_test = test.drop('t-1감사의견코드',axis=1)\n",
    "y_test = test[['t-1감사의견코드']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sc = X_train\n",
    "X_test_sc = X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sum = X_train_sc\n",
    "X_test_sum = X_test_sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "def evaluate_tabnet(X_train, y_train, X_test, y_test):\n",
    "    # Stratified 5-fold 교차검증 설정\n",
    "    cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\n",
    "\n",
    "    # 최적 하이퍼파라미터 설정 (여기서는 고정값으로 사용)\n",
    "    best_params = {\n",
    "        'n_d': 8,  # Number of decision steps (also known as the number of features for attention)\n",
    "        'n_a': 8,  # Number of attention features (output dimension of each attention head)\n",
    "        'n_steps': 3,  # Number of steps in the architecture (usually between 3 and 10)\n",
    "        'gamma': 1.5,  # The factor by which to scale the contribution of each augmented sample\n",
    "        'n_independent': 2,  # Number of independent GLU layers in each decision step\n",
    "        'n_shared': 2,  # Number of shared GLU layers in each decision step\n",
    "        'lambda_sparse': 0.001  # The sparsity loss weight\n",
    "    }\n",
    "\n",
    "    # 각 fold 별 평가 지표를 저장할 리스트 초기화\n",
    "    accuracy_list = []\n",
    "    precision_list = []\n",
    "    recall_list = []\n",
    "    f1_score_list = []\n",
    "    confusion_matrix_list = []\n",
    "\n",
    "    best_f1_score = 0\n",
    "    best_model = None\n",
    "\n",
    "    for fold_idx, (train_idx, test_idx) in enumerate(cv.split(X_train, y_train), 1):\n",
    "        X_train_fold, y_train_fold = X_train.iloc[train_idx], y_train.iloc[train_idx]\n",
    "        X_test_fold, y_test_fold = X_train.iloc[test_idx], y_train.iloc[test_idx]\n",
    "\n",
    "        # TabNet 모델 초기화\n",
    "        model = TabNetClassifier(\n",
    "            n_d=best_params['n_d'],\n",
    "            n_a=best_params['n_a'],\n",
    "            n_steps=best_params['n_steps'],\n",
    "            gamma=best_params['gamma'],\n",
    "            n_independent=best_params['n_independent'],\n",
    "            n_shared=best_params['n_shared'],\n",
    "            lambda_sparse=best_params['lambda_sparse'],\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        # 모델 학습\n",
    "        model.fit(\n",
    "            X_train_fold.values, y_train_fold.values.ravel(),  # Convert y_train to 1D array using .ravel()\n",
    "            eval_set=[(X_test_fold.values, y_test_fold.values.ravel())],  # Convert y_test to 1D array using .ravel()\n",
    "            eval_metric=['accuracy'],\n",
    "            patience=100,\n",
    "            batch_size=1024,\n",
    "            virtual_batch_size=128,\n",
    "            max_epochs=1000\n",
    "        )\n",
    "\n",
    "        # 테스트 데이터에 대한 예측\n",
    "        y_pred = model.predict(X_test_fold.values)\n",
    "\n",
    "        # 평가 지표 계산\n",
    "        accuracy = accuracy_score(y_test_fold, y_pred)\n",
    "        precision = precision_score(y_test_fold, y_pred)\n",
    "        recall = recall_score(y_test_fold, y_pred)\n",
    "        f1 = f1_score(y_test_fold, y_pred)\n",
    "        conf_matrix = confusion_matrix(y_test_fold, y_pred)\n",
    "\n",
    "        # 각 fold 별 평가 지표를 리스트에 추가\n",
    "        accuracy_list.append(accuracy)\n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "        f1_score_list.append(f1)\n",
    "        confusion_matrix_list.append(conf_matrix)\n",
    "\n",
    "        print(f\"Fold {fold_idx}\")\n",
    "        print(f\"Accuracy: {accuracy}\")\n",
    "        print(f\"Precision: {precision}\")\n",
    "        print(f\"Recall: {recall}\")\n",
    "        print(f\"F1 score: {f1}\")\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(conf_matrix)\n",
    "        print(\"------------------------------\")\n",
    "\n",
    "        # 가장 좋은 f1-score 값을 가진 모델을 저장\n",
    "        if f1 > best_f1_score:\n",
    "            best_f1_score = f1\n",
    "            best_model = model\n",
    "\n",
    "    # 가장 좋은 f1-score 값을 가진 모델로 최종 예측 수행\n",
    "    y_pred_final = best_model.predict(X_test.values)\n",
    "\n",
    "    # 평가 지표 계산\n",
    "    accuracy_final = accuracy_score(y_test, y_pred_final)\n",
    "    precision_final = precision_score(y_test, y_pred_final)\n",
    "    recall_final = recall_score(y_test, y_pred_final)\n",
    "    f1_final = f1_score(y_test, y_pred_final)\n",
    "    conf_matrix_final = confusion_matrix(y_test, y_pred_final)  # 테스트 데이터에 대한 Confusion Matrix 계산\n",
    "\n",
    "    print(\"Final Test Results\")\n",
    "    print(f\"Accuracy: {accuracy_final}\")\n",
    "    print(f\"Precision: {precision_final}\")\n",
    "    print(f\"Recall: {recall_final}\")\n",
    "    print(f\"F1 score: {f1_final}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix_final)\n",
    "\n",
    "    return accuracy_list, precision_list, recall_list, f1_score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 100 with best_epoch = 0 and best_val_0_accuracy = 0.5\n",
      "Fold 1\n",
      "Accuracy: 0.5\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1 score: 0.0\n",
      "Confusion Matrix:\n",
      "[[9 0]\n",
      " [9 0]]\n",
      "------------------------------\n",
      "\n",
      "Early stopping occurred at epoch 100 with best_epoch = 0 and best_val_0_accuracy = 0.5\n",
      "Fold 2\n",
      "Accuracy: 0.5\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1 score: 0.0\n",
      "Confusion Matrix:\n",
      "[[9 0]\n",
      " [9 0]]\n",
      "------------------------------\n",
      "\n",
      "Early stopping occurred at epoch 100 with best_epoch = 0 and best_val_0_accuracy = 0.5\n",
      "Fold 3\n",
      "Accuracy: 0.5\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1 score: 0.0\n",
      "Confusion Matrix:\n",
      "[[9 0]\n",
      " [9 0]]\n",
      "------------------------------\n",
      "\n",
      "Early stopping occurred at epoch 100 with best_epoch = 0 and best_val_0_accuracy = 0.5\n",
      "Fold 4\n",
      "Accuracy: 0.5\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1 score: 0.0\n",
      "Confusion Matrix:\n",
      "[[9 0]\n",
      " [9 0]]\n",
      "------------------------------\n",
      "\n",
      "Early stopping occurred at epoch 100 with best_epoch = 0 and best_val_0_accuracy = 0.5\n",
      "Fold 5\n",
      "Accuracy: 0.5\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1 score: 0.0\n",
      "Confusion Matrix:\n",
      "[[9 0]\n",
      " [9 0]]\n",
      "------------------------------\n",
      "\n",
      "Early stopping occurred at epoch 100 with best_epoch = 0 and best_val_0_accuracy = 0.5\n",
      "Fold 6\n",
      "Accuracy: 0.5\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1 score: 0.0\n",
      "Confusion Matrix:\n",
      "[[9 0]\n",
      " [9 0]]\n",
      "------------------------------\n",
      "\n",
      "Early stopping occurred at epoch 100 with best_epoch = 0 and best_val_0_accuracy = 0.5\n",
      "Fold 7\n",
      "Accuracy: 0.5\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1 score: 0.0\n",
      "Confusion Matrix:\n",
      "[[9 0]\n",
      " [9 0]]\n",
      "------------------------------\n",
      "\n",
      "Early stopping occurred at epoch 100 with best_epoch = 0 and best_val_0_accuracy = 0.5\n",
      "Fold 8\n",
      "Accuracy: 0.5\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1 score: 0.0\n",
      "Confusion Matrix:\n",
      "[[9 0]\n",
      " [9 0]]\n",
      "------------------------------\n",
      "\n",
      "Early stopping occurred at epoch 100 with best_epoch = 0 and best_val_0_accuracy = 0.5\n",
      "Fold 9\n",
      "Accuracy: 0.5\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1 score: 0.0\n",
      "Confusion Matrix:\n",
      "[[9 0]\n",
      " [9 0]]\n",
      "------------------------------\n",
      "\n",
      "Early stopping occurred at epoch 100 with best_epoch = 0 and best_val_0_accuracy = 0.5\n",
      "Fold 10\n",
      "Accuracy: 0.5\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1 score: 0.0\n",
      "Confusion Matrix:\n",
      "[[9 0]\n",
      " [9 0]]\n",
      "------------------------------\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# 함수를 호출하여 cross validation과 test를 수행합니다.\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m evaluate_tabnet(X_train_sum, y_train, X_test_sum, y_test)\n",
      "Cell \u001b[1;32mIn[7], line 91\u001b[0m, in \u001b[0;36mevaluate_tabnet\u001b[1;34m(X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[0;32m     88\u001b[0m         best_model \u001b[39m=\u001b[39m model\n\u001b[0;32m     90\u001b[0m \u001b[39m# 가장 좋은 f1-score 값을 가진 모델로 최종 예측 수행\u001b[39;00m\n\u001b[1;32m---> 91\u001b[0m y_pred_final \u001b[39m=\u001b[39m best_model\u001b[39m.\u001b[39;49mpredict(X_test\u001b[39m.\u001b[39mvalues)\n\u001b[0;32m     93\u001b[0m \u001b[39m# 평가 지표 계산\u001b[39;00m\n\u001b[0;32m     94\u001b[0m accuracy_final \u001b[39m=\u001b[39m accuracy_score(y_test, y_pred_final)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "# 함수를 호출하여 cross validation과 test를 수행합니다.\n",
    "evaluate_tabnet(X_train_sum, y_train, X_test_sum, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 100 with best_epoch = 0 and best_val_0_accuracy = 0.5\n",
      "Fold 1\n",
      "Accuracy: 0.5\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1 score: 0.0\n",
      "Confusion Matrix:\n",
      "[[9 0]\n",
      " [9 0]]\n",
      "------------------------------\n",
      "\n",
      "Early stopping occurred at epoch 100 with best_epoch = 0 and best_val_0_accuracy = 0.5\n",
      "Fold 2\n",
      "Accuracy: 0.5\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1 score: 0.0\n",
      "Confusion Matrix:\n",
      "[[9 0]\n",
      " [9 0]]\n",
      "------------------------------\n",
      "\n",
      "Early stopping occurred at epoch 100 with best_epoch = 0 and best_val_0_accuracy = 0.5\n",
      "Fold 3\n",
      "Accuracy: 0.5\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1 score: 0.0\n",
      "Confusion Matrix:\n",
      "[[9 0]\n",
      " [9 0]]\n",
      "------------------------------\n",
      "\n",
      "Early stopping occurred at epoch 100 with best_epoch = 0 and best_val_0_accuracy = 0.5\n",
      "Fold 4\n",
      "Accuracy: 0.5\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1 score: 0.0\n",
      "Confusion Matrix:\n",
      "[[9 0]\n",
      " [9 0]]\n",
      "------------------------------\n",
      "\n",
      "Early stopping occurred at epoch 100 with best_epoch = 0 and best_val_0_accuracy = 0.5\n",
      "Fold 5\n",
      "Accuracy: 0.5\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1 score: 0.0\n",
      "Confusion Matrix:\n",
      "[[9 0]\n",
      " [9 0]]\n",
      "------------------------------\n",
      "\n",
      "Early stopping occurred at epoch 100 with best_epoch = 0 and best_val_0_accuracy = 0.5\n",
      "Fold 6\n",
      "Accuracy: 0.5\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1 score: 0.0\n",
      "Confusion Matrix:\n",
      "[[9 0]\n",
      " [9 0]]\n",
      "------------------------------\n",
      "\n",
      "Early stopping occurred at epoch 100 with best_epoch = 0 and best_val_0_accuracy = 0.5\n",
      "Fold 7\n",
      "Accuracy: 0.5\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1 score: 0.0\n",
      "Confusion Matrix:\n",
      "[[9 0]\n",
      " [9 0]]\n",
      "------------------------------\n",
      "\n",
      "Early stopping occurred at epoch 100 with best_epoch = 0 and best_val_0_accuracy = 0.5\n",
      "Fold 8\n",
      "Accuracy: 0.5\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1 score: 0.0\n",
      "Confusion Matrix:\n",
      "[[9 0]\n",
      " [9 0]]\n",
      "------------------------------\n",
      "\n",
      "Early stopping occurred at epoch 100 with best_epoch = 0 and best_val_0_accuracy = 0.5\n",
      "Fold 9\n",
      "Accuracy: 0.5\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1 score: 0.0\n",
      "Confusion Matrix:\n",
      "[[9 0]\n",
      " [9 0]]\n",
      "------------------------------\n",
      "\n",
      "Early stopping occurred at epoch 100 with best_epoch = 0 and best_val_0_accuracy = 0.5\n",
      "Fold 10\n",
      "Accuracy: 0.5\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1 score: 0.0\n",
      "Confusion Matrix:\n",
      "[[9 0]\n",
      " [9 0]]\n",
      "------------------------------\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No best model found. Check your hyperparameters or increase the number of epochs.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 115\u001b[0m\n\u001b[0;32m    112\u001b[0m     \u001b[39mreturn\u001b[39;00m accuracy_list, precision_list, recall_list, f1_score_list\n\u001b[0;32m    114\u001b[0m \u001b[39m# 함수를 호출하여 cross validation과 test를 수행합니다.\u001b[39;00m\n\u001b[1;32m--> 115\u001b[0m evaluate_tabnet(X_train_sc, y_train, X_test_sc, y_test)\n",
      "Cell \u001b[1;32mIn[10], line 92\u001b[0m, in \u001b[0;36mevaluate_tabnet\u001b[1;34m(X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[39m# 가장 좋은 f1-score 값을 가진 모델이 없는 경우 예외 처리\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[39mif\u001b[39;00m best_model \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 92\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo best model found. Check your hyperparameters or increase the number of epochs.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     94\u001b[0m \u001b[39m# 가장 좋은 f1-score 값을 가진 모델로 최종 예측 수행\u001b[39;00m\n\u001b[0;32m     95\u001b[0m y_pred_final \u001b[39m=\u001b[39m best_model\u001b[39m.\u001b[39mpredict(X_test\u001b[39m.\u001b[39mvalues)\n",
      "\u001b[1;31mValueError\u001b[0m: No best model found. Check your hyperparameters or increase the number of epochs."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "def evaluate_tabnet(X_train, y_train, X_test, y_test):\n",
    "    # Stratified 5-fold 교차검증 설정\n",
    "    cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\n",
    "\n",
    "    # 최적 하이퍼파라미터 설정 (여기서는 고정값으로 사용)\n",
    "    best_params = {\n",
    "        'n_d': 8,  # Number of decision steps (also known as the number of features for attention)\n",
    "        'n_a': 8,  # Number of attention features (output dimension of each attention head)\n",
    "        'n_steps': 3,  # Number of steps in the architecture (usually between 3 and 10)\n",
    "        'gamma': 1.5,  # The factor by which to scale the contribution of each augmented sample\n",
    "        'n_independent': 2,  # Number of independent GLU layers in each decision step\n",
    "        'n_shared': 2,  # Number of shared GLU layers in each decision step\n",
    "        'lambda_sparse': 0.001  # The sparsity loss weight\n",
    "    }\n",
    "\n",
    "    # 각 fold 별 평가 지표를 저장할 리스트 초기화\n",
    "    accuracy_list = []\n",
    "    precision_list = []\n",
    "    recall_list = []\n",
    "    f1_score_list = []\n",
    "    confusion_matrix_list = []\n",
    "\n",
    "    best_f1_score = 0\n",
    "    best_model = None\n",
    "\n",
    "    for fold_idx, (train_idx, test_idx) in enumerate(cv.split(X_train, y_train), 1):\n",
    "        X_train_fold, y_train_fold = X_train.iloc[train_idx], y_train.iloc[train_idx]\n",
    "        X_test_fold, y_test_fold = X_train.iloc[test_idx], y_train.iloc[test_idx]\n",
    "\n",
    "        # TabNet 모델 초기화\n",
    "        model = TabNetClassifier(\n",
    "            n_d=best_params['n_d'],\n",
    "            n_a=best_params['n_a'],\n",
    "            n_steps=best_params['n_steps'],\n",
    "            gamma=best_params['gamma'],\n",
    "            n_independent=best_params['n_independent'],\n",
    "            n_shared=best_params['n_shared'],\n",
    "            lambda_sparse=best_params['lambda_sparse'],\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        # 모델 학습\n",
    "        model.fit(\n",
    "            X_train_fold.values, y_train_fold.values.ravel(),  # Convert y_train to 1D array using .ravel()\n",
    "            eval_set=[(X_test_fold.values, y_test_fold.values.ravel())],  # Convert y_test to 1D array using .ravel()\n",
    "            eval_metric=['accuracy'],\n",
    "            patience=100,\n",
    "            batch_size=1024,\n",
    "            virtual_batch_size=128,\n",
    "            max_epochs=1000\n",
    "        )\n",
    "\n",
    "        # 테스트 데이터에 대한 예측\n",
    "        y_pred = model.predict(X_test_fold.values)\n",
    "\n",
    "        # 평가 지표 계산\n",
    "        accuracy = accuracy_score(y_test_fold, y_pred)\n",
    "        precision = precision_score(y_test_fold, y_pred)\n",
    "        recall = recall_score(y_test_fold, y_pred)\n",
    "        f1 = f1_score(y_test_fold, y_pred)\n",
    "        conf_matrix = confusion_matrix(y_test_fold, y_pred)\n",
    "\n",
    "        # 각 fold 별 평가 지표를 리스트에 추가\n",
    "        accuracy_list.append(accuracy)\n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "        f1_score_list.append(f1)\n",
    "        confusion_matrix_list.append(conf_matrix)\n",
    "\n",
    "        print(f\"Fold {fold_idx}\")\n",
    "        print(f\"Accuracy: {accuracy}\")\n",
    "        print(f\"Precision: {precision}\")\n",
    "        print(f\"Recall: {recall}\")\n",
    "        print(f\"F1 score: {f1}\")\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(conf_matrix)\n",
    "        print(\"------------------------------\")\n",
    "\n",
    "        # 가장 좋은 f1-score 값을 가진 모델을 저장\n",
    "        if f1 > best_f1_score:\n",
    "            best_f1_score = f1\n",
    "            best_model = model\n",
    "\n",
    "    # 가장 좋은 f1-score 값을 가진 모델이 없는 경우 예외 처리\n",
    "    if best_model is None:\n",
    "        raise ValueError(\"No best model found. Check your hyperparameters or increase the number of epochs.\")\n",
    "\n",
    "    # 가장 좋은 f1-score 값을 가진 모델로 최종 예측 수행\n",
    "    y_pred_final = best_model.predict(X_test.values)\n",
    "\n",
    "    # 평가 지표 계산\n",
    "    accuracy_final = accuracy_score(y_test, y_pred_final)\n",
    "    precision_final = precision_score(y_test, y_pred_final)\n",
    "    recall_final = recall_score(y_test, y_pred_final)\n",
    "    f1_final = f1_score(y_test, y_pred_final)\n",
    "    conf_matrix_final = confusion_matrix(y_test, y_pred_final)  # 테스트 데이터에 대한 Confusion Matrix 계산\n",
    "\n",
    "    print(\"Final Test Results\")\n",
    "    print(f\"Accuracy: {accuracy_final}\")\n",
    "    print(f\"Precision: {precision_final}\")\n",
    "    print(f\"Recall: {recall_final}\")\n",
    "    print(f\"F1 score: {f1_final}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix_final)\n",
    "\n",
    "    return accuracy_list, precision_list, recall_list, f1_score_list\n",
    "\n",
    "# 함수를 호출하여 cross validation과 test를 수행합니다.\n",
    "evaluate_tabnet(X_train_sc, y_train, X_test_sc, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
