{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":469,"status":"ok","timestamp":1690942208577,"user":{"displayName":"유영상","userId":"15974084271948596656"},"user_tz":-540},"id":"YABpMVoh-egK"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split,KFold\n","from sklearn.preprocessing import StandardScaler\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["train=pd.read_csv('../data/train_상장_1대1.csv', encoding='euc-kr')\n","test=pd.read_csv('../data/test_상장_1대1.csv',encoding='euc-kr')"]},{"cell_type":"code","execution_count":30,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1690942212262,"user":{"displayName":"유영상","userId":"15974084271948596656"},"user_tz":-540},"id":"0DcubbyL_Pli"},"outputs":[],"source":["X_train_int=train[['부채비율', '총자본회전률', '매출액대비잉여현금흐름', 'PBR', '총자산대비영업현금흐름',\n","       '자기자본증가율', '총자본투자효율', '총자본순이익률', '매출액영업이익률']]\n","\n","X_test_int=test[['부채비율', '총자본회전률', '매출액대비잉여현금흐름', 'PBR', '총자산대비영업현금흐름',\n","       '자기자본증가율', '총자본투자효율', '총자본순이익률', '매출액영업이익률']]"]},{"cell_type":"code","execution_count":31,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1690942212262,"user":{"displayName":"유영상","userId":"15974084271948596656"},"user_tz":-540},"id":"FeHi02wm_p4X"},"outputs":[],"source":["X_train = train.drop('t-1감사의견코드',axis=1)\n","y_train = train[['t-1감사의견코드']]\n","\n","X_test = test.drop('t-1감사의견코드',axis=1)\n","y_test = test[['t-1감사의견코드']]"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n","WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/100\n"]},{"name":"stdout","output_type":"stream","text":["10/10 [==============================] - 0s 7ms/step - loss: 0.7018 - accuracy: 0.6886 - val_loss: 0.4890 - val_accuracy: 0.8356\n","Epoch 2/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.5654 - accuracy: 0.7682 - val_loss: 0.4214 - val_accuracy: 0.8356\n","Epoch 3/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.4911 - accuracy: 0.7958 - val_loss: 0.3899 - val_accuracy: 0.8767\n","Epoch 4/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.4478 - accuracy: 0.7993 - val_loss: 0.3757 - val_accuracy: 0.8767\n","Epoch 5/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.4167 - accuracy: 0.8131 - val_loss: 0.3787 - val_accuracy: 0.8767\n","Epoch 6/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.3940 - accuracy: 0.8270 - val_loss: 0.3851 - val_accuracy: 0.8630\n","Epoch 7/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.3760 - accuracy: 0.8374 - val_loss: 0.3742 - val_accuracy: 0.8767\n","Epoch 8/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.3596 - accuracy: 0.8547 - val_loss: 0.3798 - val_accuracy: 0.8219\n","Epoch 9/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.3511 - accuracy: 0.8581 - val_loss: 0.3829 - val_accuracy: 0.8219\n","Epoch 10/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.3337 - accuracy: 0.8720 - val_loss: 0.3634 - val_accuracy: 0.8630\n","Epoch 11/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.3253 - accuracy: 0.8616 - val_loss: 0.3605 - val_accuracy: 0.8493\n","Epoch 12/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.3129 - accuracy: 0.8685 - val_loss: 0.3591 - val_accuracy: 0.8493\n","Epoch 13/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.3003 - accuracy: 0.8824 - val_loss: 0.3568 - val_accuracy: 0.8356\n","Epoch 14/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.2915 - accuracy: 0.8858 - val_loss: 0.3471 - val_accuracy: 0.8767\n","Epoch 15/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.2829 - accuracy: 0.8893 - val_loss: 0.3543 - val_accuracy: 0.8630\n","Epoch 16/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.2733 - accuracy: 0.8997 - val_loss: 0.3899 - val_accuracy: 0.8219\n","Epoch 17/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.2662 - accuracy: 0.9031 - val_loss: 0.3917 - val_accuracy: 0.8219\n","Epoch 18/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.2577 - accuracy: 0.9066 - val_loss: 0.3967 - val_accuracy: 0.7945\n","Epoch 19/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.2485 - accuracy: 0.9170 - val_loss: 0.3773 - val_accuracy: 0.8082\n","Epoch 20/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.2401 - accuracy: 0.9100 - val_loss: 0.3557 - val_accuracy: 0.8219\n","Epoch 21/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.2364 - accuracy: 0.9100 - val_loss: 0.3557 - val_accuracy: 0.8219\n","Epoch 22/100\n","10/10 [==============================] - 0s 1ms/step - loss: 0.2275 - accuracy: 0.9170 - val_loss: 0.3663 - val_accuracy: 0.8356\n","Epoch 23/100\n","10/10 [==============================] - 0s 1ms/step - loss: 0.2190 - accuracy: 0.9273 - val_loss: 0.3697 - val_accuracy: 0.8356\n","Epoch 24/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.2127 - accuracy: 0.9239 - val_loss: 0.3640 - val_accuracy: 0.8219\n","Train loss: 0.2844, Train accuracy: 0.8893\n","Validation loss: 0.3471, Validation accuracy: 0.8767\n"]}],"source":["from sklearn.model_selection import train_test_split\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import EarlyStopping\n","\n","def build_model(input_dim):\n","    # Define a sequential model\n","    model = Sequential()\n","\n","    # Add the layers\n","    model.add(Dense(64, input_dim=input_dim, activation='relu'))\n","    model.add(Dense(32, activation='relu'))\n","    model.add(Dense(1, activation='sigmoid'))\n","\n","    # Compile the model\n","    model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n","\n","    return model\n","\n","# Split the data\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n","\n","# Define early stopping\n","early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n","\n","# Build the model\n","model = build_model(X_train.shape[1])\n","\n","# Fit the model\n","history = model.fit(\n","    X_train, \n","    y_train, \n","    validation_data=(X_val, y_val),\n","    epochs=100, \n","    batch_size=32, \n","    callbacks=[early_stopping]\n",")\n","\n","# Evaluate the model\n","train_loss, train_accuracy = model.evaluate(X_train, y_train, verbose=0)\n","val_loss, val_accuracy = model.evaluate(X_val, y_val, verbose=0)\n","\n","print(f'Train loss: {train_loss:.4f}, Train accuracy: {train_accuracy:.4f}')\n","print(f'Validation loss: {val_loss:.4f}, Validation accuracy: {val_accuracy:.4f}')\n"]},{"cell_type":"code","execution_count":33,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1690942246599,"user":{"displayName":"유영상","userId":"15974084271948596656"},"user_tz":-540},"id":"UKdMEwBY_xzA"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n","\n","# DNN 모델 정의\n","class DNN(nn.Module):\n","    def __init__(self, input_size, hidden_sizes, output_size):\n","        super(DNN, self).__init__()\n","        self.input_size = input_size\n","        self.hidden_sizes = hidden_sizes\n","        self.output_size = output_size\n","\n","        layers = [nn.Linear(input_size, hidden_sizes[0])]\n","        for i in range(1, len(hidden_sizes)):\n","            layers.append(nn.Linear(hidden_sizes[i-1], hidden_sizes[i]))\n","        self.hidden_layers = nn.ModuleList(layers)\n","\n","        self.output_layer = nn.Linear(hidden_sizes[-1], output_size)\n","\n","    def forward(self, x):\n","        for layer in self.hidden_layers:\n","            x = nn.ReLU()(layer(x))\n","        x = self.output_layer(x)\n","        return x\n","\n","def train_dnn_with_kfold(X_train, y_train, X_test, y_test, k):\n","    # Stratified k-fold 교차검증 설정\n","    cv = StratifiedKFold(n_splits=k, shuffle=True, random_state=0)\n","\n","    # 각 fold 별 평가 지표를 저장할 리스트 초기화\n","    accuracy_list = []\n","    precision_list = []\n","    recall_list = []\n","    f1_score_list = []\n","    confusion_matrix_list = []\n","\n","    best_f1_score = 0\n","    best_model = None\n","\n","    for fold_idx, (train_idx, val_idx) in enumerate(cv.split(X_train, y_train), 1):\n","        X_train_fold, X_val_fold = X_train.iloc[train_idx], X_train.iloc[val_idx]\n","        y_train_fold, y_val_fold = y_train.iloc[train_idx], y_train.iloc[val_idx]\n","\n","        # DNN 모델 초기화 및 학습\n","        input_size = X_train_fold.shape[1]\n","        hidden_sizes = [64, 32, 16, 8]\n","        hidden_sizes = [64, 32, 16, 8]\n","        output_size = 1\n","        model = DNN(input_size, hidden_sizes, output_size)\n","\n","        criterion = nn.BCEWithLogitsLoss()\n","        optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","        model.to(device)\n","\n","        X_train_tensor = torch.tensor(X_train_fold.values, dtype=torch.float32).to(device)\n","        y_train_tensor = torch.tensor(y_train_fold.values, dtype=torch.float32).view(-1, 1).to(device)\n","\n","        num_epochs = 1000\n","        for epoch in range(num_epochs):\n","            outputs = model(X_train_tensor)\n","            loss = criterion(outputs, y_train_tensor)\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","        # 검증 데이터에 대한 예측 및 평가\n","        X_val_tensor = torch.tensor(X_val_fold.values, dtype=torch.float32).to(device)\n","        with torch.no_grad():\n","            model.eval()\n","            y_val_pred_tensor = model(X_val_tensor)\n","            y_val_pred = (y_val_pred_tensor >= 0.5).view(-1).cpu().numpy()\n","\n","        # 평가 지표 계산\n","        accuracy = accuracy_score(y_val_fold, y_val_pred)\n","        precision = precision_score(y_val_fold, y_val_pred)\n","        recall = recall_score(y_val_fold, y_val_pred)\n","        f1 = f1_score(y_val_fold, y_val_pred)\n","        conf_matrix = confusion_matrix(y_val_fold, y_val_pred)\n","\n","        # 각 fold 별 평가 지표를 리스트에 추가\n","        accuracy_list.append(accuracy)\n","        precision_list.append(precision)\n","        recall_list.append(recall)\n","        f1_score_list.append(f1)\n","        confusion_matrix_list.append(conf_matrix)\n","\n","        print(f\"{fold_idx}번째 Fold\")\n","        print(\"평가 지표\")\n","        print(\"Accuracy:\", accuracy)\n","        print(\"Precision:\", precision)\n","        print(\"Recall:\", recall)\n","        print(\"F1 Score:\", f1)\n","        print(\"Confusion Matrix:\")\n","        print(conf_matrix)\n","        print(\"------------------------------\")\n","\n","        # 가장 좋은 F1 스코어를 가진 모델을 저장\n","        if f1 > best_f1_score:\n","            best_f1_score = f1\n","            best_model = model\n","\n","    # 전체 교차 검증 결과 출력\n","    print(\"전체 교차 검증 결과\")\n","    print(\"평균 Accuracy:\", sum(accuracy_list) / len(accuracy_list))\n","    print(\"평균 Precision:\", sum(precision_list) / len(precision_list))\n","    print(\"평균 Recall:\", sum(recall_list) / len(recall_list))\n","    print(\"평균 F1 Score:\", sum(f1_score_list) / len(f1_score_list))\n","\n","    # 가장 좋은 F1 스코어를 가진 모델로 최종 예측 수행\n","    X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32).to(device)\n","    with torch.no_grad():\n","        best_model.eval()\n","        y_test_pred_tensor = best_model(X_test_tensor)\n","        y_test_pred = (y_test_pred_tensor >= 0.5).view(-1).cpu().numpy()\n","\n","    # 테스트 데이터에 대한 평가 지표 계산\n","    accuracy_final = accuracy_score(y_test, y_test_pred)\n","    precision_final = precision_score(y_test, y_test_pred)\n","    recall_final = recall_score(y_test, y_test_pred)\n","    f1_final = f1_score(y_test, y_test_pred)\n","    conf_matrix_final = confusion_matrix(y_test, y_test_pred)\n","\n","    print(\"테스트 데이터 평가 결과\")\n","    print(\"Accuracy:\", accuracy_final)\n","    print(\"Precision:\", precision_final)\n","    print(\"Recall:\", recall_final)\n","    print(\"F1 Score:\", f1_final)\n","    print(\"Confusion Matrix:\")\n","    print(conf_matrix_final)\n","\n","    return best_model\n"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1번째 Fold\n","평가 지표\n","Accuracy: 0.7857142857142857\n","Precision: 0.625\n","Recall: 0.45454545454545453\n","F1 Score: 0.5263157894736842\n","Confusion Matrix:\n","[[28  3]\n"," [ 6  5]]\n","------------------------------\n","2번째 Fold\n","평가 지표\n","Accuracy: 0.7380952380952381\n","Precision: 0.5\n","Recall: 0.45454545454545453\n","F1 Score: 0.47619047619047616\n","Confusion Matrix:\n","[[26  5]\n"," [ 6  5]]\n","------------------------------\n","3번째 Fold\n","평가 지표\n","Accuracy: 0.8292682926829268\n","Precision: 0.6363636363636364\n","Recall: 0.7\n","F1 Score: 0.6666666666666666\n","Confusion Matrix:\n","[[27  4]\n"," [ 3  7]]\n","------------------------------\n","4번째 Fold\n","평가 지표\n","Accuracy: 0.7804878048780488\n","Precision: 0.6\n","Recall: 0.5454545454545454\n","F1 Score: 0.5714285714285713\n","Confusion Matrix:\n","[[26  4]\n"," [ 5  6]]\n","------------------------------\n","5번째 Fold\n","평가 지표\n","Accuracy: 0.8536585365853658\n","Precision: 0.8571428571428571\n","Recall: 0.5454545454545454\n","F1 Score: 0.6666666666666665\n","Confusion Matrix:\n","[[29  1]\n"," [ 5  6]]\n","------------------------------\n","6번째 Fold\n","평가 지표\n","Accuracy: 0.8536585365853658\n","Precision: 0.7272727272727273\n","Recall: 0.7272727272727273\n","F1 Score: 0.7272727272727273\n","Confusion Matrix:\n","[[27  3]\n"," [ 3  8]]\n","------------------------------\n","7번째 Fold\n","평가 지표\n","Accuracy: 0.7804878048780488\n","Precision: 0.5833333333333334\n","Recall: 0.6363636363636364\n","F1 Score: 0.6086956521739131\n","Confusion Matrix:\n","[[25  5]\n"," [ 4  7]]\n","------------------------------\n","전체 교차 검증 결과\n","평균 Accuracy: 0.8030529284884684\n","평균 Precision: 0.6470160791589362\n","평균 Recall: 0.5805194805194805\n","평균 F1 Score: 0.606176649981815\n","테스트 데이터 평가 결과\n","Accuracy: 0.8240740740740741\n","Precision: 0.6428571428571429\n","Recall: 0.6666666666666666\n","F1 Score: 0.6545454545454545\n","Confusion Matrix:\n","[[71 10]\n"," [ 9 18]]\n"]},{"data":{"text/plain":["DNN(\n","  (hidden_layers): ModuleList(\n","    (0): Linear(in_features=49, out_features=64, bias=True)\n","    (1): Linear(in_features=64, out_features=32, bias=True)\n","    (2): Linear(in_features=32, out_features=16, bias=True)\n","    (3): Linear(in_features=16, out_features=8, bias=True)\n","  )\n","  (output_layer): Linear(in_features=8, out_features=1, bias=True)\n",")"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["train_dnn_with_kfold(X_train, y_train, X_test, y_test, k=7)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMslPt6t0i1VXXo9sr8JOgH","gpuType":"T4","machine_shape":"hm","mount_file_id":"1530u3ee6bMgQ8qYx2NLdrQsA_-uD-nG6","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":0}
