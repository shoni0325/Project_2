{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6202,"status":"ok","timestamp":1691037877609,"user":{"displayName":"백두현","userId":"17317453709892656949"},"user_tz":-540},"id":"yljOTLtLeNgE","outputId":"e4d9cdcd-5fa9-4d72-e33b-d4951accc63d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting pytorch_tabnet\n","  Downloading pytorch_tabnet-4.1.0-py3-none-any.whl (44 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.5/44.5 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from pytorch_tabnet) (1.22.4)\n","Requirement already satisfied: scikit_learn>0.21 in /usr/local/lib/python3.10/dist-packages (from pytorch_tabnet) (1.2.2)\n","Requirement already satisfied: scipy>1.4 in /usr/local/lib/python3.10/dist-packages (from pytorch_tabnet) (1.10.1)\n","Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.10/dist-packages (from pytorch_tabnet) (2.0.1+cu118)\n","Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.10/dist-packages (from pytorch_tabnet) (4.65.0)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit_learn>0.21->pytorch_tabnet) (1.3.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit_learn>0.21->pytorch_tabnet) (3.2.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch_tabnet) (3.12.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch_tabnet) (4.7.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch_tabnet) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch_tabnet) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch_tabnet) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch_tabnet) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.3->pytorch_tabnet) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.3->pytorch_tabnet) (16.0.6)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3->pytorch_tabnet) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.3->pytorch_tabnet) (1.3.0)\n","Installing collected packages: pytorch_tabnet\n","Successfully installed pytorch_tabnet-4.1.0\n"]}],"source":["!pip install pytorch_tabnet"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":4130,"status":"ok","timestamp":1691038099677,"user":{"displayName":"백두현","userId":"17317453709892656949"},"user_tz":-540},"id":"l5csTZ5OcSKK"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.ticker as ticker\n","import seaborn as sns\n","from datetime import datetime\n","import time\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n","from sklearn.metrics import accuracy_score,f1_score,recall_score,precision_score,confusion_matrix,ConfusionMatrixDisplay,roc_curve,roc_auc_score,precision_recall_curve\n","from sklearn.ensemble import RandomForestClassifier , StackingClassifier\n","from sklearn.svm import SVC\n","from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n","from sklearn.tree import DecisionTreeClassifier\n","from xgboost import XGBClassifier\n","from lightgbm import LGBMClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.linear_model import LogisticRegression,Lasso\n","from sklearn.preprocessing import Binarizer\n","from sklearn.model_selection import cross_val_score,GridSearchCV\n","\n","# 한글 깨짐 방지\n","import matplotlib.pyplot as plt\n","plt.rcParams['font.family'] = 'malgun Gothic'"]},{"cell_type":"markdown","metadata":{"id":"1bxuIXbntpA3"},"source":["# OSS_1:4"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":1658,"status":"ok","timestamp":1691038101333,"user":{"displayName":"백두현","userId":"17317453709892656949"},"user_tz":-540},"id":"gATceepEcjGw"},"outputs":[],"source":["train = pd.read_csv('./OSS_0.25_train.csv', encoding='euc-kr')\n","test = pd.read_csv('./OSS_0.25_test.csv', encoding='euc-kr')"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":253,"status":"ok","timestamp":1691038108699,"user":{"displayName":"백두현","userId":"17317453709892656949"},"user_tz":-540},"id":"JzTsMiOEcoOS"},"outputs":[],"source":["X_train = train[['자기자본증가율','순운전자본회전률', '총자본증가율', '기업수명주기', '자기자본구성비율', '총자산대비잉여현금흐름', '당좌자산회전률', 'log자산총계', '총자본투자효율','총자본회전률', '자기자본회전률','총자본순이익률', '총자산대비현금흐름']]\n","y_train = train[['t-1감사의견코드']]\n","\n","X_test = test[['자기자본증가율','순운전자본회전률', '총자본증가율', '기업수명주기', '자기자본구성비율', '총자산대비잉여현금흐름', '당좌자산회전률', 'log자산총계', '총자본투자효율','총자본회전률', '자기자본회전률','총자본순이익률', '총자산대비현금흐름']]\n","y_test = test[['t-1감사의견코드']]"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":6148,"status":"ok","timestamp":1691038115838,"user":{"displayName":"백두현","userId":"17317453709892656949"},"user_tz":-540},"id":"kzYlpSyueBmd"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from pytorch_tabnet.tab_model import TabNetClassifier\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n","\n","def evaluate_tabnet(X_train, y_train, X_test, y_test):\n","    # Stratified 5-fold 교차검증 설정\n","    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n","\n","    # 최적 하이퍼파라미터 설정 (여기서는 고정값으로 사용)\n","    best_params = {\n","        'n_d': 8,  # Number of decision steps (also known as the number of features for attention)\n","        'n_a': 8,  # Number of attention features (output dimension of each attention head)\n","        'n_steps': 3,  # Number of steps in the architecture (usually between 3 and 10)\n","        'gamma': 1.5,  # The factor by which to scale the contribution of each augmented sample\n","        'n_independent': 3,  # Number of independent GLU layers in each decision step\n","        'n_shared': 3,  # Number of shared GLU layers in each decision step\n","        'lambda_sparse': 0.001  # The sparsity loss weight\n","    }\n","\n","    # 각 fold 별 평가 지표를 저장할 리스트 초기화\n","    accuracy_list = []\n","    precision_list = []\n","    recall_list = []\n","    f1_score_list = []\n","    confusion_matrix_list = []\n","\n","    best_f1_score = 0\n","    best_model = None\n","\n","    for fold_idx, (train_idx, test_idx) in enumerate(cv.split(X_train, y_train), 1):\n","        X_train_fold, y_train_fold = X_train.iloc[train_idx], y_train.iloc[train_idx]\n","        X_test_fold, y_test_fold = X_train.iloc[test_idx], y_train.iloc[test_idx]\n","\n","        # TabNet 모델 초기화\n","        model = TabNetClassifier(\n","            n_d=best_params['n_d'],\n","            n_a=best_params['n_a'],\n","            n_steps=best_params['n_steps'],\n","            gamma=best_params['gamma'],\n","            n_independent=best_params['n_independent'],\n","            n_shared=best_params['n_shared'],\n","            lambda_sparse=best_params['lambda_sparse'],\n","            verbose=0\n","        )\n","\n","        # 모델 학습\n","        model.fit(\n","            X_train_fold.values, y_train_fold.values.ravel(),  # Convert y_train to 1D array using .ravel()\n","            eval_set=[(X_test_fold.values, y_test_fold.values.ravel())],  # Convert y_test to 1D array using .ravel()\n","            eval_metric=['auc'],\n","            patience=100,\n","            batch_size=1024,\n","            virtual_batch_size=128,\n","            max_epochs=1000\n","        )\n","\n","        # 테스트 데이터에 대한 예측\n","        y_pred = model.predict(X_test_fold.values)\n","\n","        # 평가 지표 계산\n","        accuracy = accuracy_score(y_test_fold, y_pred)\n","        precision = precision_score(y_test_fold, y_pred)\n","        recall = recall_score(y_test_fold, y_pred)\n","        f1 = f1_score(y_test_fold, y_pred)\n","        conf_matrix = confusion_matrix(y_test_fold, y_pred)\n","\n","        # 각 fold 별 평가 지표를 리스트에 추가\n","        accuracy_list.append(accuracy)\n","        precision_list.append(precision)\n","        recall_list.append(recall)\n","        f1_score_list.append(f1)\n","        confusion_matrix_list.append(conf_matrix)\n","\n","        print(f\"Fold {fold_idx}\")\n","        print(f\"Accuracy: {accuracy}\")\n","        print(f\"Precision: {precision}\")\n","        print(f\"Recall: {recall}\")\n","        print(f\"F1 score: {f1}\")\n","        print(\"Confusion Matrix:\")\n","        print(conf_matrix)\n","        print(\"------------------------------\")\n","\n","        # 가장 좋은 f1-score 값을 가진 모델을 저장\n","        if f1 > best_f1_score:\n","            best_f1_score = f1\n","            best_model = model\n","\n","    # 가장 좋은 f1-score 값을 가진 모델로 최종 예측 수행\n","    y_pred_final = best_model.predict(X_test.values)\n","\n","    # 평가 지표 계산\n","    accuracy_final = accuracy_score(y_test, y_pred_final)\n","    precision_final = precision_score(y_test, y_pred_final)\n","    recall_final = recall_score(y_test, y_pred_final)\n","    f1_final = f1_score(y_test, y_pred_final)\n","    conf_matrix_final = confusion_matrix(y_test, y_pred_final)  # 테스트 데이터에 대한 Confusion Matrix 계산\n","\n","    print(\"Final Test Results\")\n","    print(f\"Accuracy: {accuracy_final}\")\n","    print(f\"Precision: {precision_final}\")\n","    print(f\"Recall: {recall_final}\")\n","    print(f\"F1 score: {f1_final}\")\n","    print(\"Confusion Matrix:\")\n","    print(conf_matrix_final)\n","\n","    return accuracy_list, precision_list, recall_list, f1_score_list"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2843828,"status":"ok","timestamp":1691040959662,"user":{"displayName":"백두현","userId":"17317453709892656949"},"user_tz":-540},"id":"uqnGdS4moJ3Q","outputId":"1f4b25ef-ad06-4daa-bb82-0b7caddcdaa2"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Early stopping occurred at epoch 137 with best_epoch = 37 and best_val_0_auc = 0.91482\n","Fold 1\n","Accuracy: 0.8952301603832535\n","Precision: 0.7462284482758621\n","Recall: 0.7213541666666666\n","F1 score: 0.7335805084745763\n","Confusion Matrix:\n","[[7211  471]\n"," [ 535 1385]]\n","------------------------------\n","\n","Early stopping occurred at epoch 313 with best_epoch = 213 and best_val_0_auc = 0.93157\n","Fold 2\n","Accuracy: 0.9053322224536555\n","Precision: 0.7693127330847096\n","Recall: 0.7520833333333333\n","F1 score: 0.7606004740584672\n","Confusion Matrix:\n","[[7249  433]\n"," [ 476 1444]]\n","------------------------------\n","\n","Early stopping occurred at epoch 265 with best_epoch = 165 and best_val_0_auc = 0.93182\n","Fold 3\n","Accuracy: 0.9073109768798167\n","Precision: 0.7946224256292906\n","Recall: 0.7234375\n","F1 score: 0.757360959651036\n","Confusion Matrix:\n","[[7323  359]\n"," [ 531 1389]]\n","------------------------------\n","\n","Early stopping occurred at epoch 145 with best_epoch = 45 and best_val_0_auc = 0.91873\n","Fold 4\n","Accuracy: 0.8917933763799208\n","Precision: 0.7546189376443418\n","Recall: 0.6803748047891723\n","F1 score: 0.7155762387079114\n","Confusion Matrix:\n","[[7256  425]\n"," [ 614 1307]]\n","------------------------------\n","\n","Early stopping occurred at epoch 231 with best_epoch = 131 and best_val_0_auc = 0.92653\n","Fold 5\n","Accuracy: 0.9027285982087065\n","Precision: 0.7761611639619473\n","Recall: 0.722019781363873\n","F1 score: 0.7481121898597627\n","Confusion Matrix:\n","[[7281  400]\n"," [ 534 1387]]\n","------------------------------\n","Final Test Results\n","Accuracy: 0.9025801952580196\n","Precision: 0.7681370761939482\n","Recall: 0.7346582984658299\n","F1 score: 0.7510247727677775\n","Confusion Matrix:\n","[[10836   636]\n"," [  761  2107]]\n"]},{"data":{"text/plain":["([0.8952301603832535,\n","  0.9053322224536555,\n","  0.9073109768798167,\n","  0.8917933763799208,\n","  0.9027285982087065],\n"," [0.7462284482758621,\n","  0.7693127330847096,\n","  0.7946224256292906,\n","  0.7546189376443418,\n","  0.7761611639619473],\n"," [0.7213541666666666,\n","  0.7520833333333333,\n","  0.7234375,\n","  0.6803748047891723,\n","  0.722019781363873],\n"," [0.7335805084745763,\n","  0.7606004740584672,\n","  0.757360959651036,\n","  0.7155762387079114,\n","  0.7481121898597627])"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["# 함수를 호출하여 cross validation과 test를 수행합니다.\n","evaluate_tabnet(X_train, y_train, X_test, y_test)"]},{"cell_type":"markdown","metadata":{"id":"9xazAVrrtwxn"},"source":["# OSS_1:3"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":1111,"status":"ok","timestamp":1691040960771,"user":{"displayName":"백두현","userId":"17317453709892656949"},"user_tz":-540},"id":"ub46UnmxoMyk"},"outputs":[],"source":["train = pd.read_csv('./OSS_0.33_train.csv', encoding='euc-kr')\n","test = pd.read_csv('./OSS_0.33_test.csv', encoding='euc-kr')"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1691040960771,"user":{"displayName":"백두현","userId":"17317453709892656949"},"user_tz":-540},"id":"R9Q3C6Mxt3pJ"},"outputs":[],"source":["X_train = train[['유동자산회전률','기업수명주기', '총자산대비잉여현금흐름','자기자본구성비율', 'log자산총계','자기자본회전률', '순운전자본회전률', '자기자본증가율', '총자본증가율', '총자산대비현금흐름', '총자본투자효율']]\n","y_train = train[['t-1감사의견코드']]\n","\n","X_test = test[['유동자산회전률','기업수명주기', '총자산대비잉여현금흐름','자기자본구성비율', 'log자산총계','자기자본회전률', '순운전자본회전률', '자기자본증가율', '총자본증가율', '총자산대비현금흐름', '총자본투자효율']]\n","y_test = test[['t-1감사의견코드']]"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1691040960772,"user":{"displayName":"백두현","userId":"17317453709892656949"},"user_tz":-540},"id":"fc2YQtRVt-HA"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from pytorch_tabnet.tab_model import TabNetClassifier\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n","\n","def evaluate_tabnet(X_train, y_train, X_test, y_test):\n","    # Stratified 5-fold 교차검증 설정\n","    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n","\n","    # 최적 하이퍼파라미터 설정 (여기서는 고정값으로 사용)\n","    best_params = {\n","        'n_d': 8,  # Number of decision steps (also known as the number of features for attention)\n","        'n_a': 8,  # Number of attention features (output dimension of each attention head)\n","        'n_steps': 3,  # Number of steps in the architecture (usually between 3 and 10)\n","        'gamma': 1.5,  # The factor by which to scale the contribution of each augmented sample\n","        'n_independent': 3,  # Number of independent GLU layers in each decision step\n","        'n_shared': 3,  # Number of shared GLU layers in each decision step\n","        'lambda_sparse': 0.001  # The sparsity loss weight\n","    }\n","\n","    # 각 fold 별 평가 지표를 저장할 리스트 초기화\n","    accuracy_list = []\n","    precision_list = []\n","    recall_list = []\n","    f1_score_list = []\n","    confusion_matrix_list = []\n","\n","    best_f1_score = 0\n","    best_model = None\n","\n","    for fold_idx, (train_idx, test_idx) in enumerate(cv.split(X_train, y_train), 1):\n","        X_train_fold, y_train_fold = X_train.iloc[train_idx], y_train.iloc[train_idx]\n","        X_test_fold, y_test_fold = X_train.iloc[test_idx], y_train.iloc[test_idx]\n","\n","        # TabNet 모델 초기화\n","        model = TabNetClassifier(\n","            n_d=best_params['n_d'],\n","            n_a=best_params['n_a'],\n","            n_steps=best_params['n_steps'],\n","            gamma=best_params['gamma'],\n","            n_independent=best_params['n_independent'],\n","            n_shared=best_params['n_shared'],\n","            lambda_sparse=best_params['lambda_sparse'],\n","            verbose=0\n","        )\n","\n","        # 모델 학습\n","        model.fit(\n","            X_train_fold.values, y_train_fold.values.ravel(),  # Convert y_train to 1D array using .ravel()\n","            eval_set=[(X_test_fold.values, y_test_fold.values.ravel())],  # Convert y_test to 1D array using .ravel()\n","            eval_metric=['auc'],\n","            patience=100,\n","            batch_size=1024,\n","            virtual_batch_size=128,\n","            max_epochs=1000\n","        )\n","\n","        # 테스트 데이터에 대한 예측\n","        y_pred = model.predict(X_test_fold.values)\n","\n","        # 평가 지표 계산\n","        accuracy = accuracy_score(y_test_fold, y_pred)\n","        precision = precision_score(y_test_fold, y_pred)\n","        recall = recall_score(y_test_fold, y_pred)\n","        f1 = f1_score(y_test_fold, y_pred)\n","        conf_matrix = confusion_matrix(y_test_fold, y_pred)\n","\n","        # 각 fold 별 평가 지표를 리스트에 추가\n","        accuracy_list.append(accuracy)\n","        precision_list.append(precision)\n","        recall_list.append(recall)\n","        f1_score_list.append(f1)\n","        confusion_matrix_list.append(conf_matrix)\n","\n","        print(f\"Fold {fold_idx}\")\n","        print(f\"Accuracy: {accuracy}\")\n","        print(f\"Precision: {precision}\")\n","        print(f\"Recall: {recall}\")\n","        print(f\"F1 score: {f1}\")\n","        print(\"Confusion Matrix:\")\n","        print(conf_matrix)\n","        print(\"------------------------------\")\n","\n","        # 가장 좋은 f1-score 값을 가진 모델을 저장\n","        if f1 > best_f1_score:\n","            best_f1_score = f1\n","            best_model = model\n","\n","    # 가장 좋은 f1-score 값을 가진 모델로 최종 예측 수행\n","    y_pred_final = best_model.predict(X_test.values)\n","\n","    # 평가 지표 계산\n","    accuracy_final = accuracy_score(y_test, y_pred_final)\n","    precision_final = precision_score(y_test, y_pred_final)\n","    recall_final = recall_score(y_test, y_pred_final)\n","    f1_final = f1_score(y_test, y_pred_final)\n","    conf_matrix_final = confusion_matrix(y_test, y_pred_final)  # 테스트 데이터에 대한 Confusion Matrix 계산\n","\n","    print(\"Final Test Results\")\n","    print(f\"Accuracy: {accuracy_final}\")\n","    print(f\"Precision: {precision_final}\")\n","    print(f\"Recall: {recall_final}\")\n","    print(f\"F1 score: {f1_final}\")\n","    print(\"Confusion Matrix:\")\n","    print(conf_matrix_final)\n","\n","    return accuracy_list, precision_list, recall_list, f1_score_list"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2645225,"status":"ok","timestamp":1691043605993,"user":{"displayName":"백두현","userId":"17317453709892656949"},"user_tz":-540},"id":"9qEcnu01uFC1","outputId":"095c4660-1b08-48eb-f9c9-8f0ffd568411"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Early stopping occurred at epoch 328 with best_epoch = 228 and best_val_0_auc = 0.9237\n","Fold 1\n","Accuracy: 0.8864341085271318\n","Precision: 0.8\n","Recall: 0.7229166666666667\n","F1 score: 0.7595075239398085\n","Confusion Matrix:\n","[[5473  347]\n"," [ 532 1388]]\n","------------------------------\n","\n","Early stopping occurred at epoch 243 with best_epoch = 143 and best_val_0_auc = 0.9207\n","Fold 2\n","Accuracy: 0.8900516795865633\n","Precision: 0.7975528364849833\n","Recall: 0.7464862051015096\n","F1 score: 0.7711750470556602\n","Confusion Matrix:\n","[[5455  364]\n"," [ 487 1434]]\n","------------------------------\n","\n","Early stopping occurred at epoch 168 with best_epoch = 68 and best_val_0_auc = 0.9231\n","Fold 3\n","Accuracy: 0.8850129198966409\n","Precision: 0.8027011156782149\n","Recall: 0.7116085372201978\n","F1 score: 0.7544150110375277\n","Confusion Matrix:\n","[[5483  336]\n"," [ 554 1367]]\n","------------------------------\n","\n","Early stopping occurred at epoch 165 with best_epoch = 65 and best_val_0_auc = 0.92322\n","Fold 4\n","Accuracy: 0.8865486496963432\n","Precision: 0.7950169875424689\n","Recall: 0.73125\n","F1 score: 0.7618014107433533\n","Confusion Matrix:\n","[[5457  362]\n"," [ 516 1404]]\n","------------------------------\n","\n","Early stopping occurred at epoch 353 with best_epoch = 253 and best_val_0_auc = 0.92281\n","Fold 5\n","Accuracy: 0.8859025713916526\n","Precision: 0.7798165137614679\n","Recall: 0.7526041666666666\n","F1 score: 0.7659687251523987\n","Confusion Matrix:\n","[[5411  408]\n"," [ 475 1445]]\n","------------------------------\n","Final Test Results\n","Accuracy: 0.8858799100190344\n","Precision: 0.7906191369606004\n","Recall: 0.7346582984658299\n","F1 score: 0.7616121453099585\n","Confusion Matrix:\n","[[8132  558]\n"," [ 761 2107]]\n"]},{"data":{"text/plain":["([0.8864341085271318,\n","  0.8900516795865633,\n","  0.8850129198966409,\n","  0.8865486496963432,\n","  0.8859025713916526],\n"," [0.8,\n","  0.7975528364849833,\n","  0.8027011156782149,\n","  0.7950169875424689,\n","  0.7798165137614679],\n"," [0.7229166666666667,\n","  0.7464862051015096,\n","  0.7116085372201978,\n","  0.73125,\n","  0.7526041666666666],\n"," [0.7595075239398085,\n","  0.7711750470556602,\n","  0.7544150110375277,\n","  0.7618014107433533,\n","  0.7659687251523987])"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["# 함수를 호출하여 cross validation과 test를 수행합니다.\n","evaluate_tabnet(X_train, y_train, X_test, y_test)"]},{"cell_type":"markdown","metadata":{"id":"TqzUDf99uGN6"},"source":["# tomek_1:4"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":2279,"status":"ok","timestamp":1691043608269,"user":{"displayName":"백두현","userId":"17317453709892656949"},"user_tz":-540},"id":"K6t4sYWBuGCI"},"outputs":[],"source":["train = pd.read_csv('./TomekLinks_0.25_train.csv', encoding='euc-kr')\n","test = pd.read_csv('./TomekLinks_0.25_test.csv', encoding='euc-kr')"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1691043608270,"user":{"displayName":"백두현","userId":"17317453709892656949"},"user_tz":-540},"id":"cSgC_BbxuXFA"},"outputs":[],"source":["X_train = train[['순운전자본회전률', '자기자본구성비율', '자기자본증가율', '총자본증가율', '유동자산회전률', 'log자산총계',\n","       '총자산대비잉여현금흐름', '기업수명주기', '영업이익증가율', '총자본투자효율', '매출액대비잉여현금흐름']]\n","y_train = train[['t-1감사의견코드']]\n","\n","X_test = test[['순운전자본회전률', '자기자본구성비율', '자기자본증가율', '총자본증가율', '유동자산회전률', 'log자산총계',\n","       '총자산대비잉여현금흐름', '기업수명주기', '영업이익증가율', '총자본투자효율', '매출액대비잉여현금흐름']]\n","y_test = test[['t-1감사의견코드']]"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1691043608270,"user":{"displayName":"백두현","userId":"17317453709892656949"},"user_tz":-540},"id":"5IX_9mAzuib8"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from pytorch_tabnet.tab_model import TabNetClassifier\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n","\n","def evaluate_tabnet(X_train, y_train, X_test, y_test):\n","    # Stratified 5-fold 교차검증 설정\n","    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n","\n","    # 최적 하이퍼파라미터 설정 (여기서는 고정값으로 사용)\n","    best_params = {\n","        'n_d': 8,  # Number of decision steps (also known as the number of features for attention)\n","        'n_a': 8,  # Number of attention features (output dimension of each attention head)\n","        'n_steps': 3,  # Number of steps in the architecture (usually between 3 and 10)\n","        'gamma': 1.5,  # The factor by which to scale the contribution of each augmented sample\n","        'n_independent': 3,  # Number of independent GLU layers in each decision step\n","        'n_shared': 3,  # Number of shared GLU layers in each decision step\n","        'lambda_sparse': 0.001  # The sparsity loss weight\n","    }\n","\n","    # 각 fold 별 평가 지표를 저장할 리스트 초기화\n","    accuracy_list = []\n","    precision_list = []\n","    recall_list = []\n","    f1_score_list = []\n","    confusion_matrix_list = []\n","\n","    best_f1_score = 0\n","    best_model = None\n","\n","    for fold_idx, (train_idx, test_idx) in enumerate(cv.split(X_train, y_train), 1):\n","        X_train_fold, y_train_fold = X_train.iloc[train_idx], y_train.iloc[train_idx]\n","        X_test_fold, y_test_fold = X_train.iloc[test_idx], y_train.iloc[test_idx]\n","\n","        # TabNet 모델 초기화\n","        model = TabNetClassifier(\n","            n_d=best_params['n_d'],\n","            n_a=best_params['n_a'],\n","            n_steps=best_params['n_steps'],\n","            gamma=best_params['gamma'],\n","            n_independent=best_params['n_independent'],\n","            n_shared=best_params['n_shared'],\n","            lambda_sparse=best_params['lambda_sparse'],\n","            verbose=0\n","        )\n","\n","        # 모델 학습\n","        model.fit(\n","            X_train_fold.values, y_train_fold.values.ravel(),  # Convert y_train to 1D array using .ravel()\n","            eval_set=[(X_test_fold.values, y_test_fold.values.ravel())],  # Convert y_test to 1D array using .ravel()\n","            eval_metric=['auc'],\n","            patience=100,\n","            batch_size=1024,\n","            virtual_batch_size=128,\n","            max_epochs=1000\n","        )\n","\n","        # 테스트 데이터에 대한 예측\n","        y_pred = model.predict(X_test_fold.values)\n","\n","        # 평가 지표 계산\n","        accuracy = accuracy_score(y_test_fold, y_pred)\n","        precision = precision_score(y_test_fold, y_pred)\n","        recall = recall_score(y_test_fold, y_pred)\n","        f1 = f1_score(y_test_fold, y_pred)\n","        conf_matrix = confusion_matrix(y_test_fold, y_pred)\n","\n","        # 각 fold 별 평가 지표를 리스트에 추가\n","        accuracy_list.append(accuracy)\n","        precision_list.append(precision)\n","        recall_list.append(recall)\n","        f1_score_list.append(f1)\n","        confusion_matrix_list.append(conf_matrix)\n","\n","        print(f\"Fold {fold_idx}\")\n","        print(f\"Accuracy: {accuracy}\")\n","        print(f\"Precision: {precision}\")\n","        print(f\"Recall: {recall}\")\n","        print(f\"F1 score: {f1}\")\n","        print(\"Confusion Matrix:\")\n","        print(conf_matrix)\n","        print(\"------------------------------\")\n","\n","        # 가장 좋은 f1-score 값을 가진 모델을 저장\n","        if f1 > best_f1_score:\n","            best_f1_score = f1\n","            best_model = model\n","\n","    # 가장 좋은 f1-score 값을 가진 모델로 최종 예측 수행\n","    y_pred_final = best_model.predict(X_test.values)\n","\n","    # 평가 지표 계산\n","    accuracy_final = accuracy_score(y_test, y_pred_final)\n","    precision_final = precision_score(y_test, y_pred_final)\n","    recall_final = recall_score(y_test, y_pred_final)\n","    f1_final = f1_score(y_test, y_pred_final)\n","    conf_matrix_final = confusion_matrix(y_test, y_pred_final)  # 테스트 데이터에 대한 Confusion Matrix 계산\n","\n","    print(\"Final Test Results\")\n","    print(f\"Accuracy: {accuracy_final}\")\n","    print(f\"Precision: {precision_final}\")\n","    print(f\"Recall: {recall_final}\")\n","    print(f\"F1 score: {f1_final}\")\n","    print(\"Confusion Matrix:\")\n","    print(conf_matrix_final)\n","\n","    return accuracy_list, precision_list, recall_list, f1_score_list"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2434059,"status":"ok","timestamp":1691046042324,"user":{"displayName":"백두현","userId":"17317453709892656949"},"user_tz":-540},"id":"ZPPQSERtumr_","outputId":"dc09c6aa-9970-4f01-bce6-2fb7afa70b69"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Early stopping occurred at epoch 117 with best_epoch = 17 and best_val_0_auc = 0.91092\n","Fold 1\n","Accuracy: 0.8914809414705269\n","Precision: 0.758235294117647\n","Recall: 0.6713541666666667\n","F1 score: 0.7121546961325966\n","Confusion Matrix:\n","[[7271  411]\n"," [ 631 1289]]\n","------------------------------\n","\n","Early stopping occurred at epoch 213 with best_epoch = 113 and best_val_0_auc = 0.9206\n","Fold 2\n","Accuracy: 0.9010622786919392\n","Precision: 0.7464430894308943\n","Recall: 0.7651041666666667\n","F1 score: 0.7556584362139916\n","Confusion Matrix:\n","[[7183  499]\n"," [ 451 1469]]\n","------------------------------\n","\n","Early stopping occurred at epoch 171 with best_epoch = 71 and best_val_0_auc = 0.93036\n","Fold 3\n","Accuracy: 0.8979379295980005\n","Precision: 0.7393075356415478\n","Recall: 0.75625\n","F1 score: 0.7476828012358393\n","Confusion Matrix:\n","[[7170  512]\n"," [ 468 1452]]\n","------------------------------\n","\n","Early stopping occurred at epoch 226 with best_epoch = 126 and best_val_0_auc = 0.91831\n","Fold 4\n","Accuracy: 0.8976254946886065\n","Precision: 0.7623042505592841\n","Recall: 0.7095262883914628\n","F1 score: 0.7349689943380966\n","Confusion Matrix:\n","[[7256  425]\n"," [ 558 1363]]\n","------------------------------\n","\n","Early stopping occurred at epoch 209 with best_epoch = 109 and best_val_0_auc = 0.91415\n","Fold 5\n","Accuracy: 0.8978337846282024\n","Precision: 0.7804295942720764\n","Recall: 0.6808953669963561\n","F1 score: 0.7272727272727274\n","Confusion Matrix:\n","[[7313  368]\n"," [ 613 1308]]\n","------------------------------\n","Final Test Results\n","Accuracy: 0.8982566248256625\n","Precision: 0.7428472940365392\n","Recall: 0.75139470013947\n","F1 score: 0.7470965505286877\n","Confusion Matrix:\n","[[10726   746]\n"," [  713  2155]]\n"]},{"data":{"text/plain":["([0.8914809414705269,\n","  0.9010622786919392,\n","  0.8979379295980005,\n","  0.8976254946886065,\n","  0.8978337846282024],\n"," [0.758235294117647,\n","  0.7464430894308943,\n","  0.7393075356415478,\n","  0.7623042505592841,\n","  0.7804295942720764],\n"," [0.6713541666666667,\n","  0.7651041666666667,\n","  0.75625,\n","  0.7095262883914628,\n","  0.6808953669963561],\n"," [0.7121546961325966,\n","  0.7556584362139916,\n","  0.7476828012358393,\n","  0.7349689943380966,\n","  0.7272727272727274])"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["# 함수를 호출하여 cross validation과 test를 수행합니다.\n","evaluate_tabnet(X_train, y_train, X_test, y_test)"]},{"cell_type":"markdown","metadata":{"id":"pgCtd7cauo4J"},"source":["# tomek_1:3"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":1071,"status":"ok","timestamp":1691046043376,"user":{"displayName":"백두현","userId":"17317453709892656949"},"user_tz":-540},"id":"YhdjIQtruq93"},"outputs":[],"source":["train = pd.read_csv('./TomekLinks_0.33_train.csv', encoding='euc-kr')\n","test = pd.read_csv('./TomekLinks_0.33_test.csv', encoding='euc-kr')"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1691046043377,"user":{"displayName":"백두현","userId":"17317453709892656949"},"user_tz":-540},"id":"Oc821qgvu8Df"},"outputs":[],"source":["X_train = train[['자기자본증가율', '자기자본회전률', '유동자산회전률', '기업수명주기', '총자산대비잉여현금흐름', '자기자본구성비율', '순운전자본회전률', '총자본증가율','log자산총계', '총자본투자효율','총자본순이익률','매출액대비잉여현금흐름','총자산대비현금흐름']]\n","y_train = train[['t-1감사의견코드']]\n","\n","X_test = test[['자기자본증가율', '자기자본회전률', '유동자산회전률', '기업수명주기', '총자산대비잉여현금흐름', '자기자본구성비율', '순운전자본회전률', '총자본증가율','log자산총계', '총자본투자효율','총자본순이익률','매출액대비잉여현금흐름','총자산대비현금흐름']]\n","y_test = test[['t-1감사의견코드']]"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1691046043377,"user":{"displayName":"백두현","userId":"17317453709892656949"},"user_tz":-540},"id":"J4HIC3_qvC2G"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from pytorch_tabnet.tab_model import TabNetClassifier\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n","\n","def evaluate_tabnet(X_train, y_train, X_test, y_test):\n","    # Stratified 5-fold 교차검증 설정\n","    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n","\n","    # 최적 하이퍼파라미터 설정 (여기서는 고정값으로 사용)\n","    best_params = {\n","        'n_d': 8,  # Number of decision steps (also known as the number of features for attention)\n","        'n_a': 8,  # Number of attention features (output dimension of each attention head)\n","        'n_steps': 3,  # Number of steps in the architecture (usually between 3 and 10)\n","        'gamma': 1.5,  # The factor by which to scale the contribution of each augmented sample\n","        'n_independent': 3,  # Number of independent GLU layers in each decision step\n","        'n_shared': 3,  # Number of shared GLU layers in each decision step\n","        'lambda_sparse': 0.001  # The sparsity loss weight\n","    }\n","\n","    # 각 fold 별 평가 지표를 저장할 리스트 초기화\n","    accuracy_list = []\n","    precision_list = []\n","    recall_list = []\n","    f1_score_list = []\n","    confusion_matrix_list = []\n","\n","    best_f1_score = 0\n","    best_model = None\n","\n","    for fold_idx, (train_idx, test_idx) in enumerate(cv.split(X_train, y_train), 1):\n","        X_train_fold, y_train_fold = X_train.iloc[train_idx], y_train.iloc[train_idx]\n","        X_test_fold, y_test_fold = X_train.iloc[test_idx], y_train.iloc[test_idx]\n","\n","        # TabNet 모델 초기화\n","        model = TabNetClassifier(\n","            n_d=best_params['n_d'],\n","            n_a=best_params['n_a'],\n","            n_steps=best_params['n_steps'],\n","            gamma=best_params['gamma'],\n","            n_independent=best_params['n_independent'],\n","            n_shared=best_params['n_shared'],\n","            lambda_sparse=best_params['lambda_sparse'],\n","            verbose=0\n","        )\n","\n","        # 모델 학습\n","        model.fit(\n","            X_train_fold.values, y_train_fold.values.ravel(),  # Convert y_train to 1D array using .ravel()\n","            eval_set=[(X_test_fold.values, y_test_fold.values.ravel())],  # Convert y_test to 1D array using .ravel()\n","            eval_metric=['auc'],\n","            patience=100,\n","            batch_size=1024,\n","            virtual_batch_size=128,\n","            max_epochs=1000\n","        )\n","\n","        # 테스트 데이터에 대한 예측\n","        y_pred = model.predict(X_test_fold.values)\n","\n","        # 평가 지표 계산\n","        accuracy = accuracy_score(y_test_fold, y_pred)\n","        precision = precision_score(y_test_fold, y_pred)\n","        recall = recall_score(y_test_fold, y_pred)\n","        f1 = f1_score(y_test_fold, y_pred)\n","        conf_matrix = confusion_matrix(y_test_fold, y_pred)\n","\n","        # 각 fold 별 평가 지표를 리스트에 추가\n","        accuracy_list.append(accuracy)\n","        precision_list.append(precision)\n","        recall_list.append(recall)\n","        f1_score_list.append(f1)\n","        confusion_matrix_list.append(conf_matrix)\n","\n","        print(f\"Fold {fold_idx}\")\n","        print(f\"Accuracy: {accuracy}\")\n","        print(f\"Precision: {precision}\")\n","        print(f\"Recall: {recall}\")\n","        print(f\"F1 score: {f1}\")\n","        print(\"Confusion Matrix:\")\n","        print(conf_matrix)\n","        print(\"------------------------------\")\n","\n","        # 가장 좋은 f1-score 값을 가진 모델을 저장\n","        if f1 > best_f1_score:\n","            best_f1_score = f1\n","            best_model = model\n","\n","    # 가장 좋은 f1-score 값을 가진 모델로 최종 예측 수행\n","    y_pred_final = best_model.predict(X_test.values)\n","\n","    # 평가 지표 계산\n","    accuracy_final = accuracy_score(y_test, y_pred_final)\n","    precision_final = precision_score(y_test, y_pred_final)\n","    recall_final = recall_score(y_test, y_pred_final)\n","    f1_final = f1_score(y_test, y_pred_final)\n","    conf_matrix_final = confusion_matrix(y_test, y_pred_final)  # 테스트 데이터에 대한 Confusion Matrix 계산\n","\n","    print(\"Final Test Results\")\n","    print(f\"Accuracy: {accuracy_final}\")\n","    print(f\"Precision: {precision_final}\")\n","    print(f\"Recall: {recall_final}\")\n","    print(f\"F1 score: {f1_final}\")\n","    print(\"Confusion Matrix:\")\n","    print(conf_matrix_final)\n","\n","    return accuracy_list, precision_list, recall_list, f1_score_list"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2139998,"status":"ok","timestamp":1691048183367,"user":{"displayName":"백두현","userId":"17317453709892656949"},"user_tz":-540},"id":"za9NPuUfvEjs","outputId":"706439c4-872d-4e00-eed6-42571f94ce28"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Early stopping occurred at epoch 178 with best_epoch = 78 and best_val_0_auc = 0.91829\n","Fold 1\n","Accuracy: 0.8863049095607235\n","Precision: 0.7576808721506442\n","Recall: 0.7963541666666667\n","F1 score: 0.7765363128491619\n","Confusion Matrix:\n","[[5331  489]\n"," [ 391 1529]]\n","------------------------------\n","\n","Early stopping occurred at epoch 131 with best_epoch = 31 and best_val_0_auc = 0.91808\n","Fold 2\n","Accuracy: 0.8890180878552971\n","Precision: 0.8020477815699659\n","Recall: 0.7339927121290994\n","F1 score: 0.7665126393041587\n","Confusion Matrix:\n","[[5471  348]\n"," [ 511 1410]]\n","------------------------------\n","\n","Early stopping occurred at epoch 155 with best_epoch = 55 and best_val_0_auc = 0.92497\n","Fold 3\n","Accuracy: 0.8908268733850129\n","Precision: 0.8091954022988506\n","Recall: 0.7329515877147319\n","F1 score: 0.7691887462441955\n","Confusion Matrix:\n","[[5487  332]\n"," [ 513 1408]]\n","------------------------------\n","\n","Early stopping occurred at epoch 313 with best_epoch = 213 and best_val_0_auc = 0.93257\n","Fold 4\n","Accuracy: 0.8962398242667011\n","Precision: 0.8260361938120256\n","Recall: 0.7369791666666666\n","F1 score: 0.7789705477566748\n","Confusion Matrix:\n","[[5521  298]\n"," [ 505 1415]]\n","------------------------------\n","\n","Early stopping occurred at epoch 233 with best_epoch = 133 and best_val_0_auc = 0.91823\n","Fold 5\n","Accuracy: 0.8813800232588189\n","Precision: 0.764799154334038\n","Recall: 0.7536458333333333\n","F1 score: 0.7591815320041972\n","Confusion Matrix:\n","[[5374  445]\n"," [ 473 1447]]\n","------------------------------\n","Final Test Results\n","Accuracy: 0.8858799100190344\n","Precision: 0.8081973736569836\n","Recall: 0.7081589958158996\n","F1 score: 0.7548782754134918\n","Confusion Matrix:\n","[[8208  482]\n"," [ 837 2031]]\n"]},{"data":{"text/plain":["([0.8863049095607235,\n","  0.8890180878552971,\n","  0.8908268733850129,\n","  0.8962398242667011,\n","  0.8813800232588189],\n"," [0.7576808721506442,\n","  0.8020477815699659,\n","  0.8091954022988506,\n","  0.8260361938120256,\n","  0.764799154334038],\n"," [0.7963541666666667,\n","  0.7339927121290994,\n","  0.7329515877147319,\n","  0.7369791666666666,\n","  0.7536458333333333],\n"," [0.7765363128491619,\n","  0.7665126393041587,\n","  0.7691887462441955,\n","  0.7789705477566748,\n","  0.7591815320041972])"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["# 함수를 호출하여 cross validation과 test를 수행합니다.\n","evaluate_tabnet(X_train, y_train, X_test, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QmciGIA1vHVH"},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNTjDO4xWSlkw32gp8q6SKI","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
