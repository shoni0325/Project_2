{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split,KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#워닝 메시지\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./Dataset/Undersampling/OSS_0.33_train.csv', encoding='euc-kr')\n",
    "test = pd.read_csv('./Dataset/Undersampling/OSS_0.33_test.csv', encoding='euc-kr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_int=train[['총자산대비잉여현금흐름', 'log자산총계', '순운전자본회전률', '총자본증가율', '자기자본구성비율', '총자본회전률',\n",
    "       '자기자본회전률', '자기자본증가율', '유동자산회전률', '총자산대비현금흐름', '총자본투자효율', '총자본순이익률']]\n",
    "\n",
    "X_test_int=test[['총자산대비잉여현금흐름', 'log자산총계', '순운전자본회전률', '총자본증가율', '자기자본구성비율', '총자본회전률',\n",
    "       '자기자본회전률', '자기자본증가율', '유동자산회전률', '총자산대비현금흐름', '총자본투자효율', '총자본순이익률']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop('t-1감사의견코드',axis=1)\n",
    "y_train = train[['t-1감사의견코드']]\n",
    "\n",
    "X_test = test.drop('t-1감사의견코드',axis=1)\n",
    "y_test = test[['t-1감사의견코드']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "def evaluate_logistic_regression(X_train, y_train, X_test, y_test):\n",
    "    # Stratified 5-fold 교차검증 설정\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "    # 최적 하이퍼파라미터 설정 (여기서는 고정값으로 사용)\n",
    "    best_params = {'C': 0.07, 'penalty': 'l2'}\n",
    "\n",
    "    # 각 fold 별 평가 지표를 저장할 리스트 초기화\n",
    "    accuracy_list = []\n",
    "    precision_list = []\n",
    "    recall_list = []\n",
    "    f1_score_list = []\n",
    "    confusion_matrix_list = []\n",
    "\n",
    "    best_f1_score = 0\n",
    "    best_model = None\n",
    "\n",
    "    for fold_idx, (train_idx, test_idx) in enumerate(cv.split(X_train, y_train), 1):\n",
    "        X_train_fold, y_train_fold = X_train.iloc[train_idx], y_train.iloc[train_idx]\n",
    "        X_test_fold, y_test_fold = X_train.iloc[test_idx], y_train.iloc[test_idx]\n",
    "\n",
    "        # 로지스틱 회귀 모델 초기화\n",
    "        model = LogisticRegression(C=best_params['C'], penalty=best_params['penalty'], n_jobs=-1)\n",
    "\n",
    "        # 모델 학습\n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "        # 테스트 데이터에 대한 예측\n",
    "        y_pred = model.predict(X_test_fold)\n",
    "\n",
    "        # 평가 지표 계산\n",
    "        accuracy = accuracy_score(y_test_fold, y_pred)\n",
    "        precision = precision_score(y_test_fold, y_pred)\n",
    "        recall = recall_score(y_test_fold, y_pred)\n",
    "        f1 = f1_score(y_test_fold, y_pred)\n",
    "        conf_matrix = confusion_matrix(y_test_fold, y_pred)\n",
    "\n",
    "        # 각 fold 별 평가 지표를 리스트에 추가\n",
    "        accuracy_list.append(accuracy)\n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "        f1_score_list.append(f1)\n",
    "        confusion_matrix_list.append(conf_matrix)\n",
    "\n",
    "        print(f\"Fold {fold_idx}\")\n",
    "        print(f\"Accuracy: {accuracy}\")\n",
    "        print(f\"Precision: {precision}\")\n",
    "        print(f\"Recall: {recall}\")\n",
    "        print(f\"F1 score: {f1}\")\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(conf_matrix)\n",
    "        print(\"------------------------------\")\n",
    "\n",
    "        # 가장 좋은 f1-score 값을 가진 모델을 저장\n",
    "        if f1 > best_f1_score:\n",
    "            best_f1_score = f1\n",
    "            best_model = model\n",
    "\n",
    "    # 가장 좋은 f1-score 값을 가진 모델로 최종 예측 수행\n",
    "    y_pred_final = best_model.predict(X_test)\n",
    "\n",
    "    # 평가 지표 계산\n",
    "    accuracy_final = accuracy_score(y_test, y_pred_final)\n",
    "    precision_final = precision_score(y_test, y_pred_final)\n",
    "    recall_final = recall_score(y_test, y_pred_final)\n",
    "    f1_final = f1_score(y_test, y_pred_final)\n",
    "    conf_matrix_final = confusion_matrix(y_test, y_pred_final)\n",
    "\n",
    "    print(\"Final Test Results\")\n",
    "    print(f\"Accuracy: {accuracy_final}\")\n",
    "    print(f\"Precision: {precision_final}\")\n",
    "    print(f\"Recall: {recall_final}\")\n",
    "    print(f\"F1 score: {f1_final}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix_final)\n",
    "\n",
    "    return accuracy_final, precision_final, recall_final, f1_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Accuracy: 0.8361757105943153\n",
      "Precision: 0.7393538913362702\n",
      "Recall: 0.5244791666666667\n",
      "F1 score: 0.6136502132845826\n",
      "Confusion Matrix:\n",
      "[[5465  355]\n",
      " [ 913 1007]]\n",
      "------------------------------\n",
      "Fold 2\n",
      "Accuracy: 0.8301033591731266\n",
      "Precision: 0.7214912280701754\n",
      "Recall: 0.5137948984903696\n",
      "F1 score: 0.6001824262693828\n",
      "Confusion Matrix:\n",
      "[[5438  381]\n",
      " [ 934  987]]\n",
      "------------------------------\n",
      "Fold 3\n",
      "Accuracy: 0.8368217054263566\n",
      "Precision: 0.746996996996997\n",
      "Recall: 0.5179593961478397\n",
      "F1 score: 0.6117430064555794\n",
      "Confusion Matrix:\n",
      "[[5482  337]\n",
      " [ 926  995]]\n",
      "------------------------------\n",
      "Fold 4\n",
      "Accuracy: 0.839901796097687\n",
      "Precision: 0.7409766454352441\n",
      "Recall: 0.5453125\n",
      "F1 score: 0.6282628262826282\n",
      "Confusion Matrix:\n",
      "[[5453  366]\n",
      " [ 873 1047]]\n",
      "------------------------------\n",
      "Fold 5\n",
      "Accuracy: 0.832536503424215\n",
      "Precision: 0.7342342342342343\n",
      "Recall: 0.509375\n",
      "F1 score: 0.6014760147601476\n",
      "Confusion Matrix:\n",
      "[[5465  354]\n",
      " [ 942  978]]\n",
      "------------------------------\n",
      "Final Test Results\n",
      "Accuracy: 0.837082540231874\n",
      "Precision: 0.7481108312342569\n",
      "Recall: 0.5177824267782427\n",
      "F1 score: 0.6119925819080982\n",
      "Confusion Matrix:\n",
      "[[8190  500]\n",
      " [1383 1485]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.837082540231874, 0.7481108312342569, 0.5177824267782427, 0.6119925819080982)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_logistic_regression(X_train_int, y_train, X_test_int, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Randomforest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "def evaluate_random_forest(X_train, y_train, X_test, y_test):\n",
    "    # Stratified 5-fold 교차검증 설정\n",
    "    cv = StratifiedKFold(n_splits=7, shuffle=True, random_state=0)\n",
    "\n",
    "    # 최적 하이퍼파라미터 설정 (여기서는 고정값으로 사용)\n",
    "    best_params = {'max_depth': 9, 'min_samples_leaf': 20, 'max_features':'auto', 'n_estimators':200}\n",
    "\n",
    "    # 각 fold 별 평가 지표를 저장할 리스트 초기화\n",
    "    accuracy_list = []\n",
    "    precision_list = []\n",
    "    recall_list = []\n",
    "    f1_score_list = []\n",
    "    confusion_matrix_list = []\n",
    "\n",
    "    best_f1_score = 0\n",
    "    best_model = None\n",
    "\n",
    "    for fold_idx, (train_idx, test_idx) in enumerate(cv.split(X_train, y_train), 1):\n",
    "        X_train_fold, y_train_fold = X_train.iloc[train_idx], y_train.iloc[train_idx]\n",
    "        X_test_fold, y_test_fold = X_train.iloc[test_idx], y_train.iloc[test_idx]\n",
    "\n",
    "        # 랜덤 포레스트 모델 초기화\n",
    "        model = RandomForestClassifier(max_depth=best_params['max_depth'],\n",
    "                                       min_samples_leaf=best_params['min_samples_leaf'],\n",
    "                                       n_estimators=best_params['n_estimators'],\n",
    "                                       max_features= best_params['max_features'],\n",
    "                                       random_state=0)\n",
    "\n",
    "        # 모델 학습\n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "        # 테스트 데이터에 대한 예측 확률 얻기\n",
    "        probabilities = model.predict_proba(X_test_fold)\n",
    "\n",
    "        # threshold를 0.4로 설정하여 예측 클래스를 조정\n",
    "        threshold = 0.43\n",
    "        predicted_classes = (probabilities[:, 1] > threshold).astype(np.int)\n",
    "\n",
    "        # 평가 지표 계산\n",
    "        accuracy = accuracy_score(y_test_fold, predicted_classes)\n",
    "        precision = precision_score(y_test_fold, predicted_classes)\n",
    "        recall = recall_score(y_test_fold, predicted_classes)\n",
    "        f1 = f1_score(y_test_fold, predicted_classes)\n",
    "        conf_matrix = confusion_matrix(y_test_fold, predicted_classes)\n",
    "\n",
    "        # 각 fold 별 평가 지표를 리스트에 추가\n",
    "        accuracy_list.append(accuracy)\n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "        f1_score_list.append(f1)\n",
    "        confusion_matrix_list.append(conf_matrix)\n",
    "\n",
    "        print(f\"Fold {fold_idx}\")\n",
    "        print(f\"Accuracy: {accuracy}\")\n",
    "        print(f\"Precision: {precision}\")\n",
    "        print(f\"Recall: {recall}\")\n",
    "        print(f\"F1 score: {f1}\")\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(conf_matrix)\n",
    "        print(\"------------------------------\")\n",
    "\n",
    "        # 가장 좋은 f1-score 값을 가진 모델을 저장\n",
    "        if f1 > best_f1_score:\n",
    "            best_f1_score = f1\n",
    "            best_model = model\n",
    "\n",
    "    # 가장 좋은 f1-score 값을 가진 모델로 최종 예측 수행\n",
    "    probabilities_final = best_model.predict_proba(X_test)\n",
    "    y_pred_final = (probabilities_final[:, 1] > threshold).astype(np.int)\n",
    "\n",
    "    # 평가 지표 계산\n",
    "    accuracy_final = accuracy_score(y_test, y_pred_final)\n",
    "    precision_final = precision_score(y_test, y_pred_final)\n",
    "    recall_final = recall_score(y_test, y_pred_final)\n",
    "    f1_final = f1_score(y_test, y_pred_final)\n",
    "    conf_matrix_final = confusion_matrix(y_test, y_pred_final)\n",
    "\n",
    "    print(\"Final Test Results\")\n",
    "    print(f\"Accuracy: {accuracy_final}\")\n",
    "    print(f\"Precision: {precision_final}\")\n",
    "    print(f\"Recall: {recall_final}\")\n",
    "    print(f\"F1 score: {f1_final}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix_final)\n",
    "\n",
    "    return accuracy_list, precision_list, recall_list, f1_score_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Accuracy: 0.8934707903780069\n",
      "Precision: 0.7758985200845666\n",
      "Recall: 0.8024781341107872\n",
      "F1 score: 0.7889645288427086\n",
      "Confusion Matrix:\n",
      "[[3839  318]\n",
      " [ 271 1101]]\n",
      "------------------------------\n",
      "Fold 2\n",
      "Accuracy: 0.8913004159884247\n",
      "Precision: 0.7675225537820958\n",
      "Recall: 0.8061224489795918\n",
      "F1 score: 0.7863490934944898\n",
      "Confusion Matrix:\n",
      "[[3822  335]\n",
      " [ 266 1106]]\n",
      "------------------------------\n",
      "Fold 3\n",
      "Accuracy: 0.8901953690303908\n",
      "Precision: 0.7776162790697675\n",
      "Recall: 0.7804522246535376\n",
      "F1 score: 0.779031670913724\n",
      "Confusion Matrix:\n",
      "[[3851  306]\n",
      " [ 301 1070]]\n",
      "------------------------------\n",
      "Fold 4\n",
      "Accuracy: 0.8925470332850941\n",
      "Precision: 0.7809110629067245\n",
      "Recall: 0.787746170678337\n",
      "F1 score: 0.7843137254901961\n",
      "Confusion Matrix:\n",
      "[[3854  303]\n",
      " [ 291 1080]]\n",
      "------------------------------\n",
      "Fold 5\n",
      "Accuracy: 0.8939942112879884\n",
      "Precision: 0.7688098495212038\n",
      "Recall: 0.8192419825072886\n",
      "F1 score: 0.7932251235003529\n",
      "Confusion Matrix:\n",
      "[[3818  338]\n",
      " [ 248 1124]]\n",
      "------------------------------\n",
      "Fold 6\n",
      "Accuracy: 0.8869392185238785\n",
      "Precision: 0.7588357588357588\n",
      "Recall: 0.7981049562682215\n",
      "F1 score: 0.77797513321492\n",
      "Confusion Matrix:\n",
      "[[3808  348]\n",
      " [ 277 1095]]\n",
      "------------------------------\n",
      "Fold 7\n",
      "Accuracy: 0.8880246020260492\n",
      "Precision: 0.7638402242466713\n",
      "Recall: 0.7944606413994169\n",
      "F1 score: 0.7788495891389782\n",
      "Confusion Matrix:\n",
      "[[3819  337]\n",
      " [ 282 1090]]\n",
      "------------------------------\n",
      "Final Test Results\n",
      "Accuracy: 0.8897733171829036\n",
      "Precision: 0.7733196159122085\n",
      "Recall: 0.7862622036262203\n",
      "F1 score: 0.7797372060857538\n",
      "Confusion Matrix:\n",
      "[[8029  661]\n",
      " [ 613 2255]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.8934707903780069,\n",
       "  0.8913004159884247,\n",
       "  0.8901953690303908,\n",
       "  0.8925470332850941,\n",
       "  0.8939942112879884,\n",
       "  0.8869392185238785,\n",
       "  0.8880246020260492],\n",
       " [0.7758985200845666,\n",
       "  0.7675225537820958,\n",
       "  0.7776162790697675,\n",
       "  0.7809110629067245,\n",
       "  0.7688098495212038,\n",
       "  0.7588357588357588,\n",
       "  0.7638402242466713],\n",
       " [0.8024781341107872,\n",
       "  0.8061224489795918,\n",
       "  0.7804522246535376,\n",
       "  0.787746170678337,\n",
       "  0.8192419825072886,\n",
       "  0.7981049562682215,\n",
       "  0.7944606413994169],\n",
       " [0.7889645288427086,\n",
       "  0.7863490934944898,\n",
       "  0.779031670913724,\n",
       "  0.7843137254901961,\n",
       "  0.7932251235003529,\n",
       "  0.77797513321492,\n",
       "  0.7788495891389782])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_random_forest(X_train_int, y_train, X_test_int, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "def evaluate_lgbm(X_train, y_train, X_test, y_test, k_fold=5):\n",
    "    # Stratified k-fold 교차검증 설정\n",
    "    cv = StratifiedKFold(n_splits=k_fold, shuffle=True, random_state=0)\n",
    "\n",
    "    # LGBM 하이퍼파라미터 설정 (여기서는 고정값으로 사용)\n",
    "    params = {\n",
    "        'max_depth': 20,\n",
    "        'min_child_samples': 10,\n",
    "        'n_estimators':180,\n",
    "        'learning_rate': 0.1,\n",
    "        'objective': 'binary',\n",
    "        'random_state': 0\n",
    "    }\n",
    "\n",
    "    # 각 fold 별 평가 지표를 저장할 리스트 초기화\n",
    "    accuracy_list = []\n",
    "    precision_list = []\n",
    "    recall_list = []\n",
    "    f1_score_list = []\n",
    "    confusion_matrix_list = []\n",
    "\n",
    "    best_f1_score = 0\n",
    "    best_model = None\n",
    "\n",
    "    for fold_idx, (train_idx, test_idx) in enumerate(cv.split(X_train, y_train), 1):\n",
    "        X_train_fold, y_train_fold = X_train.iloc[train_idx], y_train.iloc[train_idx]\n",
    "        X_test_fold, y_test_fold = X_train.iloc[test_idx], y_train.iloc[test_idx]\n",
    "\n",
    "        # LGBM 모델 초기화\n",
    "        model = lgb.LGBMClassifier(**params)\n",
    "\n",
    "        # 모델 학습\n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "        # 테스트 데이터에 대한 예측 확률 얻기\n",
    "        probabilities = model.predict_proba(X_test_fold)\n",
    "\n",
    "        # threshold를 0.4로 설정하여 예측 클래스를 조정\n",
    "        threshold = 0.5\n",
    "        predicted_classes = (probabilities[:, 1] > threshold).astype(np.int)\n",
    "\n",
    "        # 평가 지표 계산\n",
    "        accuracy = accuracy_score(y_test_fold, predicted_classes)\n",
    "        precision = precision_score(y_test_fold, predicted_classes)\n",
    "        recall = recall_score(y_test_fold, predicted_classes)\n",
    "        f1 = f1_score(y_test_fold, predicted_classes)\n",
    "        conf_matrix = confusion_matrix(y_test_fold, predicted_classes)\n",
    "\n",
    "        # 각 fold 별 평가 지표를 리스트에 추가\n",
    "        accuracy_list.append(accuracy)\n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "        f1_score_list.append(f1)\n",
    "        confusion_matrix_list.append(conf_matrix)\n",
    "\n",
    "        print(f\"Fold {fold_idx}\")\n",
    "        print(f\"Accuracy: {accuracy}\")\n",
    "        print(f\"Precision: {precision}\")\n",
    "        print(f\"Recall: {recall}\")\n",
    "        print(f\"F1 score: {f1}\")\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(conf_matrix)\n",
    "        print(\"------------------------------\")\n",
    "\n",
    "        # 가장 좋은 f1-score 값을 가진 모델을 저장\n",
    "        if f1 > best_f1_score:\n",
    "            best_f1_score = f1\n",
    "            best_model = model\n",
    "\n",
    "    # 가장 좋은 f1-score 값을 가진 모델로 최종 예측 수행\n",
    "    probabilities_final = best_model.predict_proba(X_test)\n",
    "    y_pred_final = (probabilities_final[:, 1] > threshold).astype(np.int)\n",
    "\n",
    "    # 평가 지표 계산\n",
    "    accuracy_final = accuracy_score(y_test, y_pred_final)\n",
    "    precision_final = precision_score(y_test, y_pred_final)\n",
    "    recall_final = recall_score(y_test, y_pred_final)\n",
    "    f1_final = f1_score(y_test, y_pred_final)\n",
    "    conf_matrix_final = confusion_matrix(y_test, y_pred_final)\n",
    "\n",
    "    print(\"Final Test Results\")\n",
    "    print(f\"Accuracy: {accuracy_final}\")\n",
    "    print(f\"Precision: {precision_final}\")\n",
    "    print(f\"Recall: {recall_final}\")\n",
    "    print(f\"F1 score: {f1_final}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix_final)\n",
    "\n",
    "    return accuracy_list, precision_list, recall_list, f1_score_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Accuracy: 0.891343669250646\n",
      "Precision: 0.7972451790633609\n",
      "Recall: 0.7536458333333333\n",
      "F1 score: 0.7748326639892905\n",
      "Confusion Matrix:\n",
      "[[5452  368]\n",
      " [ 473 1447]]\n",
      "------------------------------\n",
      "Fold 2\n",
      "Accuracy: 0.8988372093023256\n",
      "Precision: 0.8105895196506551\n",
      "Recall: 0.7730348776678813\n",
      "F1 score: 0.7913669064748202\n",
      "Confusion Matrix:\n",
      "[[5472  347]\n",
      " [ 436 1485]]\n",
      "------------------------------\n",
      "Fold 3\n",
      "Accuracy: 0.8939276485788114\n",
      "Precision: 0.8042035398230089\n",
      "Recall: 0.7568974492451848\n",
      "F1 score: 0.7798337355859479\n",
      "Confusion Matrix:\n",
      "[[5465  354]\n",
      " [ 467 1454]]\n",
      "------------------------------\n",
      "Fold 4\n",
      "Accuracy: 0.8953353146401344\n",
      "Precision: 0.7942735949098622\n",
      "Recall: 0.7802083333333333\n",
      "F1 score: 0.7871781397792957\n",
      "Confusion Matrix:\n",
      "[[5431  388]\n",
      " [ 422 1498]]\n",
      "------------------------------\n",
      "Fold 5\n",
      "Accuracy: 0.8944308050135676\n",
      "Precision: 0.7992403689636463\n",
      "Recall: 0.7671875\n",
      "F1 score: 0.7828859952165825\n",
      "Confusion Matrix:\n",
      "[[5449  370]\n",
      " [ 447 1473]]\n",
      "------------------------------\n",
      "Final Test Results\n",
      "Accuracy: 0.8946184460979408\n",
      "Precision: 0.8080657206870799\n",
      "Recall: 0.7545327754532776\n",
      "F1 score: 0.7803822574828705\n",
      "Confusion Matrix:\n",
      "[[8176  514]\n",
      " [ 704 2164]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.891343669250646,\n",
       "  0.8988372093023256,\n",
       "  0.8939276485788114,\n",
       "  0.8953353146401344,\n",
       "  0.8944308050135676],\n",
       " [0.7972451790633609,\n",
       "  0.8105895196506551,\n",
       "  0.8042035398230089,\n",
       "  0.7942735949098622,\n",
       "  0.7992403689636463],\n",
       " [0.7536458333333333,\n",
       "  0.7730348776678813,\n",
       "  0.7568974492451848,\n",
       "  0.7802083333333333,\n",
       "  0.7671875],\n",
       " [0.7748326639892905,\n",
       "  0.7913669064748202,\n",
       "  0.7798337355859479,\n",
       "  0.7871781397792957,\n",
       "  0.7828859952165825])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_lgbm(X_train_int, y_train, X_test_int, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "def perform_lgbm_grid_search(X_train, y_train, k_fold=5):\n",
    "    # Stratified k-fold 교차검증 설정\n",
    "    cv = StratifiedKFold(n_splits=k_fold, shuffle=True, random_state=0)\n",
    "\n",
    "    # LGBM 하이퍼파라미터 후보 리스트 설정\n",
    "    param_grid = {\n",
    "        'max_depth': [16],\n",
    "        'n_estimators': [220],\n",
    "        'learning_rate': [0.08],\n",
    "        'objective': ['binary'],\n",
    "        'random_state': [0],\n",
    "        'min_child_samples' :[20]\n",
    "    }\n",
    "\n",
    "    # LGBM 모델 초기화\n",
    "    model = lgb.LGBMClassifier()\n",
    "\n",
    "    # 그리드 서치 설정\n",
    "    grid_search = GridSearchCV(model, param_grid, scoring='recall', cv=cv, verbose=1, n_jobs=-1)\n",
    "\n",
    "    # 모델 학습 및 튜닝\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # 최적 하이퍼파라미터 출력\n",
    "    print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "    # 평균 평가 지표 계산\n",
    "    mean_f1_score = np.mean(grid_search.cv_results_['mean_test_score'])\n",
    "    print(\"Mean F1 Score:\", mean_f1_score)\n",
    "\n",
    "    return grid_search.best_params_, mean_f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "def evaluate_lgbm_with_best_params(X_train, y_train, X_test, y_test, best_params, k_fold=5):\n",
    "    # Stratified k-fold 교차검증 설정\n",
    "    cv = StratifiedKFold(n_splits=k_fold, shuffle=True, random_state=0)\n",
    "\n",
    "    # LGBM 모델 초기화\n",
    "    model = lgb.LGBMClassifier(**best_params)\n",
    "\n",
    "    # 각 fold 별 평가 지표를 저장할 리스트 초기화\n",
    "    accuracy_list = []\n",
    "    precision_list = []\n",
    "    recall_list = []\n",
    "    f1_score_list = []\n",
    "    confusion_matrix_list = []\n",
    "\n",
    "    best_f1_score = 0\n",
    "    best_model = None\n",
    "\n",
    "    for fold_idx, (train_idx, test_idx) in enumerate(cv.split(X_train, y_train), 1):\n",
    "        X_train_fold, y_train_fold = X_train.iloc[train_idx], y_train.iloc[train_idx]\n",
    "        X_test_fold, y_test_fold = X_train.iloc[test_idx], y_train.iloc[test_idx]\n",
    "\n",
    "        # 모델 학습\n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "        # 테스트 데이터에 대한 예측 확률 얻기\n",
    "        probabilities = model.predict_proba(X_test_fold)\n",
    "\n",
    "        # threshold를 0.4로 설정하여 예측 클래스를 조정\n",
    "        threshold = 0.4\n",
    "        predicted_classes = (probabilities[:, 1] > threshold).astype(np.int)\n",
    "\n",
    "        # 평가 지표 계산\n",
    "        accuracy = accuracy_score(y_test_fold, predicted_classes)\n",
    "        precision = precision_score(y_test_fold, predicted_classes)\n",
    "        recall = recall_score(y_test_fold, predicted_classes)\n",
    "        f1 = f1_score(y_test_fold, predicted_classes)\n",
    "        conf_matrix = confusion_matrix(y_test_fold, predicted_classes)\n",
    "\n",
    "        # 각 fold 별 평가 지표를 리스트에 추가\n",
    "        accuracy_list.append(accuracy)\n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "        f1_score_list.append(f1)\n",
    "        confusion_matrix_list.append(conf_matrix)\n",
    "\n",
    "        print(f\"Fold {fold_idx}\")\n",
    "        print(f\"Accuracy: {accuracy}\")\n",
    "        print(f\"Precision: {precision}\")\n",
    "        print(f\"Recall: {recall}\")\n",
    "        print(f\"F1 score: {f1}\")\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(conf_matrix)\n",
    "        print(\"------------------------------\")\n",
    "\n",
    "        # 가장 좋은 f1-score 값을 가진 모델을 저장\n",
    "        if f1 > best_f1_score:\n",
    "            best_f1_score = f1\n",
    "            best_model = model\n",
    "\n",
    "    # 가장 좋은 f1-score 값을 가진 모델로 최종 예측 수행\n",
    "    probabilities_final = best_model.predict_proba(X_test)\n",
    "    y_pred_final = (probabilities_final[:, 1] > threshold).astype(np.int)\n",
    "\n",
    "    # 평가 지표 계산\n",
    "    accuracy_final = accuracy_score(y_test, y_pred_final)\n",
    "    precision_final = precision_score(y_test, y_pred_final)\n",
    "    recall_final = recall_score(y_test, y_pred_final)\n",
    "    f1_final = f1_score(y_test, y_pred_final)\n",
    "    conf_matrix_final = confusion_matrix(y_test, y_pred_final)\n",
    "\n",
    "    print(\"Final Test Results\")\n",
    "    print(f\"Accuracy: {accuracy_final}\")\n",
    "    print(f\"Precision: {precision_final}\")\n",
    "    print(f\"Recall: {recall_final}\")\n",
    "    print(f\"F1 score: {f1_final}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix_final)\n",
    "\n",
    "    return accuracy_list, precision_list, recall_list, f1_score_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 7 folds for each of 1 candidates, totalling 7 fits\n",
      "Best Hyperparameters: {'learning_rate': 0.08, 'max_depth': 16, 'min_child_samples': 20, 'n_estimators': 220, 'objective': 'binary', 'random_state': 0}\n",
      "Mean F1 Score: 0.7611923794212903\n",
      "Fold 1\n",
      "Accuracy: 0.8947368421052632\n",
      "Precision: 0.7777777777777778\n",
      "Recall: 0.8061224489795918\n",
      "F1 score: 0.7916964924838941\n",
      "Confusion Matrix:\n",
      "[[3841  316]\n",
      " [ 266 1106]]\n",
      "------------------------------\n",
      "Fold 2\n",
      "Accuracy: 0.8903960933260987\n",
      "Precision: 0.7656033287101248\n",
      "Recall: 0.8046647230320699\n",
      "F1 score: 0.7846481876332622\n",
      "Confusion Matrix:\n",
      "[[3819  338]\n",
      " [ 268 1104]]\n",
      "------------------------------\n",
      "Fold 3\n",
      "Accuracy: 0.8914616497829233\n",
      "Precision: 0.7767408470926059\n",
      "Recall: 0.7892049598832969\n",
      "F1 score: 0.7829232995658467\n",
      "Confusion Matrix:\n",
      "[[3846  311]\n",
      " [ 289 1082]]\n",
      "------------------------------\n",
      "Fold 4\n",
      "Accuracy: 0.8974312590448625\n",
      "Precision: 0.7896253602305475\n",
      "Recall: 0.799416484318016\n",
      "F1 score: 0.794490757520841\n",
      "Confusion Matrix:\n",
      "[[3865  292]\n",
      " [ 275 1096]]\n",
      "------------------------------\n",
      "Fold 5\n",
      "Accuracy: 0.8959840810419681\n",
      "Precision: 0.7712729748127978\n",
      "Recall: 0.825801749271137\n",
      "F1 score: 0.7976064765927491\n",
      "Confusion Matrix:\n",
      "[[3820  336]\n",
      " [ 239 1133]]\n",
      "------------------------------\n",
      "Fold 6\n",
      "Accuracy: 0.8873010130246021\n",
      "Precision: 0.7559808612440191\n",
      "Recall: 0.8061224489795918\n",
      "F1 score: 0.7802469135802469\n",
      "Confusion Matrix:\n",
      "[[3799  357]\n",
      " [ 266 1106]]\n",
      "------------------------------\n",
      "Fold 7\n",
      "Accuracy: 0.8873010130246021\n",
      "Precision: 0.7617051013277428\n",
      "Recall: 0.7944606413994169\n",
      "F1 score: 0.7777381377095968\n",
      "Confusion Matrix:\n",
      "[[3815  341]\n",
      " [ 282 1090]]\n",
      "------------------------------\n",
      "Final Test Results\n",
      "Accuracy: 0.8936667243467727\n",
      "Precision: 0.7799795011957635\n",
      "Recall: 0.7960251046025104\n",
      "F1 score: 0.787920621225194\n",
      "Confusion Matrix:\n",
      "[[8046  644]\n",
      " [ 585 2283]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.8947368421052632,\n",
       "  0.8903960933260987,\n",
       "  0.8914616497829233,\n",
       "  0.8974312590448625,\n",
       "  0.8959840810419681,\n",
       "  0.8873010130246021,\n",
       "  0.8873010130246021],\n",
       " [0.7777777777777778,\n",
       "  0.7656033287101248,\n",
       "  0.7767408470926059,\n",
       "  0.7896253602305475,\n",
       "  0.7712729748127978,\n",
       "  0.7559808612440191,\n",
       "  0.7617051013277428],\n",
       " [0.8061224489795918,\n",
       "  0.8046647230320699,\n",
       "  0.7892049598832969,\n",
       "  0.799416484318016,\n",
       "  0.825801749271137,\n",
       "  0.8061224489795918,\n",
       "  0.7944606413994169],\n",
       " [0.7916964924838941,\n",
       "  0.7846481876332622,\n",
       "  0.7829232995658467,\n",
       "  0.794490757520841,\n",
       "  0.7976064765927491,\n",
       "  0.7802469135802469,\n",
       "  0.7777381377095968])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params, mean_f1_score = perform_lgbm_grid_search(X_train, y_train, k_fold=7)\n",
    "evaluate_lgbm_with_best_params(X_train_int, y_train, X_test_int, y_test, best_params, k_fold=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "def perform_xgb_grid_search(X_train, y_train, k_fold=5):\n",
    "    # Stratified k-fold 교차검증 설정\n",
    "    cv = StratifiedKFold(n_splits=k_fold, shuffle=True, random_state=0)\n",
    "\n",
    "    # XGBoost 하이퍼파라미터 후보 리스트 설정\n",
    "    param_grid = {\n",
    "        'max_depth': [6, 8, 10],\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'learning_rate': [0.01, 0.1, 0.3],\n",
    "        'objective': ['binary:logistic'],\n",
    "        'random_state': [0],\n",
    "    }\n",
    "\n",
    "    # XGBoost 모델 초기화\n",
    "    model = xgb.XGBClassifier()\n",
    "\n",
    "    # 그리드 서치 설정\n",
    "    grid_search = GridSearchCV(model, param_grid, scoring='f1', cv=cv, verbose=1, n_jobs=-1)\n",
    "\n",
    "    # 모델 학습 및 튜닝\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # 최적 하이퍼파라미터 출력\n",
    "    print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "    # 평균 평가 지표 계산\n",
    "    mean_f1_score = np.mean(grid_search.cv_results_['mean_test_score'])\n",
    "    print(\"Mean F1 Score:\", mean_f1_score)\n",
    "\n",
    "    return grid_search.best_params_, mean_f1_score\n",
    "\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "def evaluate_xgb_with_best_params(X_train, y_train, X_test, y_test, best_params, k_fold=5):\n",
    "    # Stratified k-fold 교차검증 설정\n",
    "    cv = StratifiedKFold(n_splits=k_fold, shuffle=True, random_state=0)\n",
    "\n",
    "    # XGBoost 모델 초기화\n",
    "    model = xgb.XGBClassifier(**best_params)\n",
    "\n",
    "    # 각 fold 별 평가 지표를 저장할 리스트 초기화\n",
    "    accuracy_list = []\n",
    "    precision_list = []\n",
    "    recall_list = []\n",
    "    f1_score_list = []\n",
    "    confusion_matrix_list = []\n",
    "\n",
    "    best_f1_score = 0\n",
    "    best_model = None\n",
    "\n",
    "    for fold_idx, (train_idx, test_idx) in enumerate(cv.split(X_train, y_train), 1):\n",
    "        X_train_fold, y_train_fold = X_train.iloc[train_idx], y_train.iloc[train_idx]\n",
    "        X_test_fold, y_test_fold = X_train.iloc[test_idx], y_train.iloc[test_idx]\n",
    "\n",
    "        # 모델 학습\n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "        # 테스트 데이터에 대한 예측 확률 얻기\n",
    "        probabilities = model.predict_proba(X_test_fold)\n",
    "\n",
    "        # threshold를 0.4로 설정하여 예측 클래스를 조정\n",
    "        threshold = 0.4\n",
    "        predicted_classes = (probabilities[:, 1] > threshold).astype(np.int)\n",
    "\n",
    "        # 평가 지표 계산\n",
    "        accuracy = accuracy_score(y_test_fold, predicted_classes)\n",
    "        precision = precision_score(y_test_fold, predicted_classes)\n",
    "        recall = recall_score(y_test_fold, predicted_classes)\n",
    "        f1 = f1_score(y_test_fold, predicted_classes)\n",
    "        conf_matrix = confusion_matrix(y_test_fold, predicted_classes)\n",
    "\n",
    "        # 각 fold 별 평가 지표를 리스트에 추가\n",
    "        accuracy_list.append(accuracy)\n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "        f1_score_list.append(f1)\n",
    "        confusion_matrix_list.append(conf_matrix)\n",
    "\n",
    "        print(f\"Fold {fold_idx}\")\n",
    "        print(f\"Accuracy: {accuracy}\")\n",
    "        print(f\"Precision: {precision}\")\n",
    "        print(f\"Recall: {recall}\")\n",
    "        print(f\"F1 score: {f1}\")\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(conf_matrix)\n",
    "        print(\"------------------------------\")\n",
    "\n",
    "        # 가장 좋은 f1-score 값을 가진 모델을 저장\n",
    "        if f1 > best_f1_score:\n",
    "            best_f1_score = f1\n",
    "            best_model = model\n",
    "\n",
    "    # 가장 좋은 f1-score 값을 가진 모델로 최종 예측 수행\n",
    "    probabilities_final = best_model.predict_proba(X_test)\n",
    "    y_pred_final = (probabilities_final[:, 1] > threshold).astype(np.int)\n",
    "\n",
    "    # 평가 지표 계산\n",
    "    accuracy_final = accuracy_score(y_test, y_pred_final)\n",
    "    precision_final = precision_score(y_test, y_pred_final)\n",
    "    recall_final = recall_score(y_test, y_pred_final)\n",
    "    f1_final = f1_score(y_test, y_pred_final)\n",
    "    conf_matrix_final = confusion_matrix(y_test, y_pred_final)\n",
    "\n",
    "    print(\"Final Test Results\")\n",
    "    print(f\"Accuracy: {accuracy_final}\")\n",
    "    print(f\"Precision: {precision_final}\")\n",
    "    print(f\"Recall: {recall_final}\")\n",
    "    print(f\"F1 score: {f1_final}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix_final)\n",
    "\n",
    "    return accuracy_list, precision_list, recall_list, f1_score_list\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"
     ]
    }
   ],
   "source": [
    "best_params, mean_f1_score = perform_xgb_grid_search(X_train, y_train, k_fold=5)\n",
    "evaluate_xgb_with_best_params(X_train_int, y_train, X_test_int, y_test, best_params, k_fold=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
