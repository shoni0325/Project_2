{"cells":[{"cell_type":"code","execution_count":65,"metadata":{"executionInfo":{"elapsed":469,"status":"ok","timestamp":1690942208577,"user":{"displayName":"유영상","userId":"15974084271948596656"},"user_tz":-540},"id":"YABpMVoh-egK"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split,KFold\n","from sklearn.preprocessing import StandardScaler"]},{"cell_type":"code","execution_count":66,"metadata":{"executionInfo":{"elapsed":3084,"status":"ok","timestamp":1690942212261,"user":{"displayName":"유영상","userId":"15974084271948596656"},"user_tz":-540},"id":"yultI1-Y-9S8"},"outputs":[],"source":["train=pd.read_csv('./Dataset/Undersampling_0.33_train.csv',index_col=False, encoding='euc-kr')\n","test=pd.read_csv('./Dataset/Undersampling_0.33_test.csv',index_col=False,encoding='euc-kr')"]},{"cell_type":"code","execution_count":67,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1690942212262,"user":{"displayName":"유영상","userId":"15974084271948596656"},"user_tz":-540},"id":"0DcubbyL_Pli"},"outputs":[],"source":["X_train_int=train[['부채비율', '총자본회전률', '매출액대비잉여현금흐름', 'PBR', '총자산대비영업현금흐름',\n","'자기자본증가율', '총자본투자효율', '총자본순이익률', '매출액영업이익률']]\n","\n","X_test_int=test[['부채비율', '총자본회전률', '매출액대비잉여현금흐름', 'PBR', '총자산대비영업현금흐름',\n","'자기자본증가율', '총자본투자효율', '총자본순이익률', '매출액영업이익률']]"]},{"cell_type":"code","execution_count":68,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1690942212262,"user":{"displayName":"유영상","userId":"15974084271948596656"},"user_tz":-540},"id":"FeHi02wm_p4X"},"outputs":[],"source":["X_train = train.drop('t-1감사의견코드',axis=1)\n","y_train = train[['t-1감사의견코드']]\n","\n","X_test = test.drop('t-1감사의견코드',axis=1)\n","y_test = test[['t-1감사의견코드']]"]},{"cell_type":"code","execution_count":69,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1690942212263,"user":{"displayName":"유영상","userId":"15974084271948596656"},"user_tz":-540},"id":"Dao53YjZ_sb6"},"outputs":[],"source":["X_train_sc = X_train\n","X_test_sc = X_test"]},{"cell_type":"code","execution_count":70,"metadata":{},"outputs":[],"source":["X_train_sum =X_train_sc\n","X_test_sum =X_test_sc"]},{"cell_type":"code","execution_count":71,"metadata":{},"outputs":[],"source":["from sklearn.model_selection import StratifiedKFold, GridSearchCV\n","from sklearn.linear_model import LogisticRegression\n","import numpy as np\n","\n","def perform_logit_grid_search(X_train, y_train, k_fold=5):\n","    # Stratified k-fold cross validation setup\n","    cv = StratifiedKFold(n_splits=k_fold, shuffle=True, random_state=0)\n","\n","    # Logistic Regression hyperparameter candidate list setup\n","    param_grid = {\n","        'C': [0.1,0.5,1],\n","        'penalty': ['l1', 'l2', 'elasticnet'],\n","        'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n","        'random_state': [0]\n","    }\n","\n","    # Initialize a Logistic Regression model\n","    model = LogisticRegression()\n","\n","    # Grid search setup\n","    grid_search = GridSearchCV(model, param_grid, scoring='f1', cv=cv, verbose=1, n_jobs=-1)\n","\n","    # Fit the model and tune\n","    grid_search.fit(X_train, y_train)\n","\n","    # Print the best hyperparameters\n","    print(\"Best Hyperparameters:\", grid_search.best_params_)\n","\n","    # Calculate the average evaluation metric\n","    mean_f1_score = np.mean(grid_search.cv_results_['mean_test_score'])\n","    print(\"Mean F1 Score:\", mean_f1_score)\n","\n","    return grid_search.best_params_, mean_f1_score\n"]},{"cell_type":"code","execution_count":72,"metadata":{},"outputs":[],"source":["from sklearn.model_selection import StratifiedKFold\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n","from sklearn.linear_model import LogisticRegression\n","import numpy as np\n","\n","def evaluate_logit_with_best_params(X_train, y_train, X_test, y_test, best_params, k_fold=5):\n","    # Stratified k-fold cross validation setup\n","    cv = StratifiedKFold(n_splits=k_fold, shuffle=True, random_state=0)\n","\n","    # Initialize a Logistic Regression model\n","    model = LogisticRegression(**best_params)\n","\n","    # Lists to save the evaluation metrics for each fold\n","    accuracy_list = []\n","    precision_list = []\n","    recall_list = []\n","    f1_score_list = []\n","    confusion_matrix_list = []\n","\n","    best_f1_score = 0\n","    best_model = None\n","\n","    for fold_idx, (train_idx, test_idx) in enumerate(cv.split(X_train, y_train), 1):\n","        X_train_fold, y_train_fold = X_train.iloc[train_idx], y_train.iloc[train_idx]\n","        X_test_fold, y_test_fold = X_train.iloc[test_idx], y_train.iloc[test_idx]\n","\n","        # Fit the model\n","        model.fit(X_train_fold, y_train_fold)\n","\n","        # Get the predicted probabilities on the test data\n","        probabilities = model.predict_proba(X_test_fold)\n","\n","        # Adjust the predicted classes with a threshold of 0.5\n","        threshold = 0.395\n","        predicted_classes = (probabilities[:, 1] > threshold).astype(np.int)\n","\n","        # Calculate the evaluation metrics\n","        accuracy = accuracy_score(y_test_fold, predicted_classes)\n","        precision = precision_score(y_test_fold, predicted_classes)\n","        recall = recall_score(y_test_fold, predicted_classes)\n","        f1 = f1_score(y_test_fold, predicted_classes)\n","        conf_matrix = confusion_matrix(y_test_fold, predicted_classes)\n","\n","        # Append the evaluation metrics for each fold to the lists\n","        accuracy_list.append(accuracy)\n","        precision_list.append(precision)\n","        recall_list.append(recall)\n","        f1_score_list.append(f1)\n","        confusion_matrix_list.append(conf_matrix)\n","\n","        print(f\"Fold {fold_idx}\")\n","        print(f\"Accuracy: {accuracy}\")\n","        print(f\"Precision: {precision}\")\n","        print(f\"Recall: {recall}\")\n","        print(f\"F1 score: {f1}\")\n","        print(\"Confusion Matrix:\")\n","        print(conf_matrix)\n","        print(\"------------------------------\")\n","\n","        # Save the model with the best F1 score\n","        if f1 > best_f1_score:\n","            best_f1_score = f1\n","            best_model = model\n","\n","\n","    # Perform the final prediction with the model with the best F1 score\n","    probabilities_final = best_model.predict_proba(X_test)\n","    y_pred_final = (probabilities_final[:, 1] > threshold).astype(np.int)\n","\n","    # Calculate the evaluation metrics\n","    accuracy_final = accuracy_score(y_test, y_pred_final)\n","    precision_final = precision_score(y_test, y_pred_final)\n","    recall_final = recall_score(y_test, y_pred_final)\n","    f1_final = f1_score(y_test, y_pred_final)\n","    conf_matrix_final = confusion_matrix(y_test, y_pred_final)\n","\n","    print(\"Final Test Results\")\n","    print(f\"Accuracy: {accuracy_final}\")\n","    print(f\"Precision: {precision_final}\")\n","    print(f\"Recall: {recall_final}\")\n","    print(f\"F1 score: {f1_final}\")\n","    print(\"Confusion Matrix:\")\n","    print(conf_matrix_final)\n","\n","    return accuracy_list, precision_list, recall_list, f1_score_list\n"]},{"cell_type":"code","execution_count":73,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 7 folds for each of 45 candidates, totalling 315 fits\n","Best Hyperparameters: {'C': 0.5, 'penalty': 'l2', 'random_state': 0, 'solver': 'liblinear'}\n","Mean F1 Score: nan\n","Fold 1\n","Accuracy: 0.8269230769230769\n","Precision: 0.6666666666666666\n","Recall: 0.6153846153846154\n","F1 score: 0.64\n","Confusion Matrix:\n","[[35  4]\n"," [ 5  8]]\n","------------------------------\n","Fold 2\n","Accuracy: 0.8653846153846154\n","Precision: 0.8\n","Recall: 0.6153846153846154\n","F1 score: 0.6956521739130435\n","Confusion Matrix:\n","[[37  2]\n"," [ 5  8]]\n","------------------------------\n","Fold 3\n","Accuracy: 0.7307692307692307\n","Precision: 0.42857142857142855\n","Recall: 0.23076923076923078\n","F1 score: 0.3\n","Confusion Matrix:\n","[[35  4]\n"," [10  3]]\n","------------------------------\n","Fold 4\n","Accuracy: 0.8076923076923077\n","Precision: 0.6\n","Recall: 0.6923076923076923\n","F1 score: 0.6428571428571429\n","Confusion Matrix:\n","[[33  6]\n"," [ 4  9]]\n","------------------------------\n","Fold 5\n","Accuracy: 0.8653846153846154\n","Precision: 0.7142857142857143\n","Recall: 0.7692307692307693\n","F1 score: 0.7407407407407408\n","Confusion Matrix:\n","[[35  4]\n"," [ 3 10]]\n","------------------------------\n","Fold 6\n","Accuracy: 0.7450980392156863\n","Precision: 0.4444444444444444\n","Recall: 0.3333333333333333\n","F1 score: 0.380952380952381\n","Confusion Matrix:\n","[[34  5]\n"," [ 8  4]]\n","------------------------------\n","Fold 7\n","Accuracy: 0.8823529411764706\n","Precision: 1.0\n","Recall: 0.5384615384615384\n","F1 score: 0.7000000000000001\n","Confusion Matrix:\n","[[38  0]\n"," [ 6  7]]\n","------------------------------\n","Final Test Results\n","Accuracy: 0.7777777777777778\n","Precision: 0.5652173913043478\n","Recall: 0.48148148148148145\n","F1 score: 0.52\n","Confusion Matrix:\n","[[71 10]\n"," [14 13]]\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\dgh06\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n","168 fits failed out of a total of 315.\n","The score on these train-test partitions for these parameters will be set to nan.\n","If these failures are not expected, you can try to debug them by setting error_score='raise'.\n","\n","Below are more details about the failures:\n","--------------------------------------------------------------------------------\n","21 fits failed with the following error:\n","Traceback (most recent call last):\n","  File \"c:\\Users\\dgh06\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n","    estimator.fit(X_train, y_train, **fit_params)\n","  File \"c:\\Users\\dgh06\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n","    solver = _check_solver(self.solver, self.penalty, self.dual)\n","  File \"c:\\Users\\dgh06\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n","    raise ValueError(\n","ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n","\n","--------------------------------------------------------------------------------\n","21 fits failed with the following error:\n","Traceback (most recent call last):\n","  File \"c:\\Users\\dgh06\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n","    estimator.fit(X_train, y_train, **fit_params)\n","  File \"c:\\Users\\dgh06\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n","    solver = _check_solver(self.solver, self.penalty, self.dual)\n","  File \"c:\\Users\\dgh06\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n","    raise ValueError(\n","ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n","\n","--------------------------------------------------------------------------------\n","21 fits failed with the following error:\n","Traceback (most recent call last):\n","  File \"c:\\Users\\dgh06\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n","    estimator.fit(X_train, y_train, **fit_params)\n","  File \"c:\\Users\\dgh06\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n","    solver = _check_solver(self.solver, self.penalty, self.dual)\n","  File \"c:\\Users\\dgh06\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n","    raise ValueError(\n","ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n","\n","--------------------------------------------------------------------------------\n","21 fits failed with the following error:\n","Traceback (most recent call last):\n","  File \"c:\\Users\\dgh06\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n","    estimator.fit(X_train, y_train, **fit_params)\n","  File \"c:\\Users\\dgh06\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n","    solver = _check_solver(self.solver, self.penalty, self.dual)\n","  File \"c:\\Users\\dgh06\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n","    raise ValueError(\n","ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n","\n","--------------------------------------------------------------------------------\n","21 fits failed with the following error:\n","Traceback (most recent call last):\n","  File \"c:\\Users\\dgh06\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n","    estimator.fit(X_train, y_train, **fit_params)\n","  File \"c:\\Users\\dgh06\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n","    solver = _check_solver(self.solver, self.penalty, self.dual)\n","  File \"c:\\Users\\dgh06\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n","    raise ValueError(\n","ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n","\n","--------------------------------------------------------------------------------\n","21 fits failed with the following error:\n","Traceback (most recent call last):\n","  File \"c:\\Users\\dgh06\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n","    estimator.fit(X_train, y_train, **fit_params)\n","  File \"c:\\Users\\dgh06\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n","    solver = _check_solver(self.solver, self.penalty, self.dual)\n","  File \"c:\\Users\\dgh06\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 64, in _check_solver\n","    raise ValueError(\n","ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n","\n","--------------------------------------------------------------------------------\n","21 fits failed with the following error:\n","Traceback (most recent call last):\n","  File \"c:\\Users\\dgh06\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n","    estimator.fit(X_train, y_train, **fit_params)\n","  File \"c:\\Users\\dgh06\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n","    solver = _check_solver(self.solver, self.penalty, self.dual)\n","  File \"c:\\Users\\dgh06\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n","    raise ValueError(\n","ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n","\n","--------------------------------------------------------------------------------\n","21 fits failed with the following error:\n","Traceback (most recent call last):\n","  File \"c:\\Users\\dgh06\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n","    estimator.fit(X_train, y_train, **fit_params)\n","  File \"c:\\Users\\dgh06\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1291, in fit\n","    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n","  File \"c:\\Users\\dgh06\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 63, in __call__\n","    return super().__call__(iterable_with_config)\n","  File \"c:\\Users\\dgh06\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py\", line 1085, in __call__\n","    if self.dispatch_one_batch(iterator):\n","  File \"c:\\Users\\dgh06\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py\", line 901, in dispatch_one_batch\n","    self._dispatch(tasks)\n","  File \"c:\\Users\\dgh06\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py\", line 819, in _dispatch\n","    job = self._backend.apply_async(batch, callback=cb)\n","  File \"c:\\Users\\dgh06\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n","    result = ImmediateResult(func)\n","  File \"c:\\Users\\dgh06\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 597, in __init__\n","    self.results = batch()\n","  File \"c:\\Users\\dgh06\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py\", line 288, in __call__\n","    return [func(*args, **kwargs)\n","  File \"c:\\Users\\dgh06\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py\", line 288, in <listcomp>\n","    return [func(*args, **kwargs)\n","  File \"c:\\Users\\dgh06\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 123, in __call__\n","    return self.function(*args, **kwargs)\n","  File \"c:\\Users\\dgh06\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 521, in _logistic_regression_path\n","    alpha = (1.0 / C) * (1 - l1_ratio)\n","TypeError: unsupported operand type(s) for -: 'int' and 'NoneType'\n","\n","  warnings.warn(some_fits_failed_message, FitFailedWarning)\n","c:\\Users\\dgh06\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.51658936        nan 0.4948532  0.51965303\n"," 0.51965303 0.51846556 0.52583732 0.52281735        nan        nan\n","        nan        nan        nan        nan        nan 0.51230943\n","        nan 0.51341991 0.53789949 0.53789949 0.54415188 0.51206475\n"," 0.53547848        nan        nan        nan        nan        nan\n","        nan        nan 0.51719813        nan 0.52341229 0.5426856\n"," 0.5426856  0.51435489 0.52442849 0.53362319        nan        nan\n","        nan        nan        nan]\n","  warnings.warn(\n","c:\\Users\\dgh06\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","c:\\Users\\dgh06\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","C:\\Users\\dgh06\\AppData\\Local\\Temp\\ipykernel_28856\\1137693707.py:35: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  predicted_classes = (probabilities[:, 1] > threshold).astype(np.int)\n","c:\\Users\\dgh06\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","C:\\Users\\dgh06\\AppData\\Local\\Temp\\ipykernel_28856\\1137693707.py:35: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  predicted_classes = (probabilities[:, 1] > threshold).astype(np.int)\n","c:\\Users\\dgh06\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","C:\\Users\\dgh06\\AppData\\Local\\Temp\\ipykernel_28856\\1137693707.py:35: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  predicted_classes = (probabilities[:, 1] > threshold).astype(np.int)\n","c:\\Users\\dgh06\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","C:\\Users\\dgh06\\AppData\\Local\\Temp\\ipykernel_28856\\1137693707.py:35: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  predicted_classes = (probabilities[:, 1] > threshold).astype(np.int)\n","c:\\Users\\dgh06\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","C:\\Users\\dgh06\\AppData\\Local\\Temp\\ipykernel_28856\\1137693707.py:35: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  predicted_classes = (probabilities[:, 1] > threshold).astype(np.int)\n","c:\\Users\\dgh06\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","C:\\Users\\dgh06\\AppData\\Local\\Temp\\ipykernel_28856\\1137693707.py:35: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  predicted_classes = (probabilities[:, 1] > threshold).astype(np.int)\n","c:\\Users\\dgh06\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","C:\\Users\\dgh06\\AppData\\Local\\Temp\\ipykernel_28856\\1137693707.py:35: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  predicted_classes = (probabilities[:, 1] > threshold).astype(np.int)\n","C:\\Users\\dgh06\\AppData\\Local\\Temp\\ipykernel_28856\\1137693707.py:68: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  y_pred_final = (probabilities_final[:, 1] > threshold).astype(np.int)\n"]},{"data":{"text/plain":["([0.8269230769230769,\n","  0.8653846153846154,\n","  0.7307692307692307,\n","  0.8076923076923077,\n","  0.8653846153846154,\n","  0.7450980392156863,\n","  0.8823529411764706],\n"," [0.6666666666666666,\n","  0.8,\n","  0.42857142857142855,\n","  0.6,\n","  0.7142857142857143,\n","  0.4444444444444444,\n","  1.0],\n"," [0.6153846153846154,\n","  0.6153846153846154,\n","  0.23076923076923078,\n","  0.6923076923076923,\n","  0.7692307692307693,\n","  0.3333333333333333,\n","  0.5384615384615384],\n"," [0.64,\n","  0.6956521739130435,\n","  0.3,\n","  0.6428571428571429,\n","  0.7407407407407408,\n","  0.380952380952381,\n","  0.7000000000000001])"]},"execution_count":73,"metadata":{},"output_type":"execute_result"}],"source":["best_params, mean_f1_score = perform_logit_grid_search(X_train, y_train, k_fold=7)\n","evaluate_logit_with_best_params(X_train_int, y_train, X_test_int, y_test, best_params, k_fold=7)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMslPt6t0i1VXXo9sr8JOgH","gpuType":"T4","machine_shape":"hm","mount_file_id":"1530u3ee6bMgQ8qYx2NLdrQsA_-uD-nG6","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":0}
