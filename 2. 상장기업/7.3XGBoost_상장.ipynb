{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":469,"status":"ok","timestamp":1690942208577,"user":{"displayName":"유영상","userId":"15974084271948596656"},"user_tz":-540},"id":"YABpMVoh-egK"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split,KFold\n","from sklearn.preprocessing import StandardScaler"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["train=pd.read_csv('/Users/taewon/Documents/금융 빅데이터/Project_2/코딩/상장기업/sampling data/Undersampling_0.33_train.csv',index_col=False, encoding='euc-kr')\n","test=pd.read_csv('/Users/taewon/Documents/금융 빅데이터/Project_2/코딩/상장기업/sampling data/Undersampling_0.33_test.csv',index_col=False,encoding='euc-kr')"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["X_train_int=train[['부가가치율', '자기자본구성비율', '총자산대비영업현금흐름', '자기자본순이익률', '총자본순이익률', '총자본회전률',\n","       'PBR', '이윤분배율', '자기자본증가율', '차입금의존도', 'log자산총계', 'PER', '연구개발비대비매출액',\n","       '유동자산회전률']]\n","\n","X_test_int=test[['부가가치율', '자기자본구성비율', '총자산대비영업현금흐름', '자기자본순이익률', '총자본순이익률', '총자본회전률',\n","       'PBR', '이윤분배율', '자기자본증가율', '차입금의존도', 'log자산총계', 'PER', '연구개발비대비매출액',\n","       '유동자산회전률']]"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1690942212262,"user":{"displayName":"유영상","userId":"15974084271948596656"},"user_tz":-540},"id":"FeHi02wm_p4X"},"outputs":[],"source":["X_train = train.drop('t-1감사의견코드',axis=1)\n","y_train = train[['t-1감사의견코드']]\n","\n","X_test = test.drop('t-1감사의견코드',axis=1)\n","y_test = test[['t-1감사의견코드']]"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1690942212263,"user":{"displayName":"유영상","userId":"15974084271948596656"},"user_tz":-540},"id":"Dao53YjZ_sb6"},"outputs":[],"source":["X_train_sc = X_train\n","X_test_sc = X_test"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["X_train_sum =X_train_sc\n","X_test_sum =X_test_sc"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["from sklearn.model_selection import StratifiedKFold, GridSearchCV\n","from xgboost import XGBClassifier\n","import numpy as np\n","\n","def perform_xgb_grid_search(X_train, y_train, k_fold=5):\n","    # Stratified k-fold cross validation setup\n","    cv = StratifiedKFold(n_splits=k_fold, shuffle=True, random_state=0)\n","\n","    # XGBoost hyperparameter candidate list setup\n","    param_grid = {\n","        'max_depth': [3, 5, 7],\n","        'n_estimators': [100, 200, 300],\n","        'learning_rate': [0.01, 0.1, 0.2],\n","        'objective': ['binary:logistic'],\n","        'random_state': [0]\n","    }\n","\n","    # Initialize an XGBoost classifier\n","    model = XGBClassifier(use_label_encoder=False)\n","\n","    # Grid search setup\n","    grid_search = GridSearchCV(model, param_grid, scoring='f1', cv=cv, verbose=1, n_jobs=-1)\n","\n","    # Fit the model and tune\n","    grid_search.fit(X_train, y_train)\n","\n","    # Print the best hyperparameters\n","    print(\"Best Hyperparameters:\", grid_search.best_params_)\n","\n","    # Calculate the average evaluation metric\n","    mean_f1_score = np.mean(grid_search.cv_results_['mean_test_score'])\n","    print(\"Mean F1 Score:\", mean_f1_score)\n","\n","    return grid_search.best_params_, mean_f1_score\n"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["from sklearn.model_selection import StratifiedKFold\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n","from xgboost import XGBClassifier\n","import numpy as np\n","\n","def evaluate_xgb_with_best_params(X_train, y_train, X_test, y_test, best_params, k_fold=5):\n","    # Stratified k-fold cross validation setup\n","    cv = StratifiedKFold(n_splits=k_fold, shuffle=True, random_state=0)\n","\n","    # Initialize an XGBoost model\n","    model = XGBClassifier(**best_params, use_label_encoder=False)\n","\n","    # Lists to save the evaluation metrics for each fold\n","    accuracy_list = []\n","    precision_list = []\n","    recall_list = []\n","    f1_score_list = []\n","    confusion_matrix_list = []\n","\n","    best_f1_score = 0\n","    best_model = None\n","\n","    for fold_idx, (train_idx, test_idx) in enumerate(cv.split(X_train, y_train), 1):\n","        X_train_fold, y_train_fold = X_train.iloc[train_idx], y_train.iloc[train_idx]\n","        X_test_fold, y_test_fold = X_train.iloc[test_idx], y_train.iloc[test_idx]\n","\n","        # Fit the model\n","        model.fit(X_train_fold, y_train_fold)\n","\n","        # Get the predicted probabilities on the test data\n","        probabilities = model.predict_proba(X_test_fold)\n","\n","        # Adjust the predicted classes with a threshold of 0.5\n","        threshold = 0.5\n","        predicted_classes = (probabilities[:, 1] > threshold).astype(np.int)\n","\n","        # Calculate the evaluation metrics\n","        accuracy = accuracy_score(y_test_fold, predicted_classes)\n","        precision = precision_score(y_test_fold, predicted_classes)\n","        recall = recall_score(y_test_fold, predicted_classes)\n","        f1 = f1_score(y_test_fold, predicted_classes)\n","        conf_matrix = confusion_matrix(y_test_fold, predicted_classes)\n","\n","        # Append the evaluation metrics for each fold to the lists\n","        accuracy_list.append(accuracy)\n","        precision_list.append(precision)\n","        recall_list.append(recall)\n","        f1_score_list.append(f1)\n","        confusion_matrix_list.append(conf_matrix)\n","\n","        print(f\"Fold {fold_idx}\")\n","        print(f\"Accuracy: {accuracy}\")\n","        print(f\"Precision: {precision}\")\n","        print(f\"Recall: {recall}\")\n","        print(f\"F1 score: {f1}\")\n","        print(\"Confusion Matrix:\")\n","        print(conf_matrix)\n","        print(\"------------------------------\")\n","\n","        # Save the model with the best F1 score\n","        if f1 > best_f1_score:\n","            best_f1_score = f1\n","            best_model = model\n","\n","    # Perform the final prediction with the model with the best F1 score\n","    probabilities_final = best_model.predict_proba(X_test)\n","    y_pred_final = (probabilities_final[:, 1] > threshold).astype(np.int)\n","\n","    # Calculate the evaluation metrics\n","    accuracy_final = accuracy_score(y_test, y_pred_final)\n","    precision_final = precision_score(y_test, y_pred_final)\n","    recall_final = recall_score(y_test, y_pred_final)\n","    f1_final = f1_score(y_test, y_pred_final)\n","    conf_matrix_final = confusion_matrix(y_test, y_pred_final)\n","\n","    print(\"Final Test Results\")\n","    print(f\"Accuracy: {accuracy_final}\")\n","    print(f\"Precision: {precision_final}\")\n","    print(f\"Recall: {recall_final}\")\n","    print(f\"F1 score: {f1_final}\")\n","    print(\"Confusion Matrix:\")\n","    print(conf_matrix_final)\n","\n","    return accuracy_list, precision_list, recall_list, f1_score_list\n"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"]},{"name":"stderr","output_type":"stream","text":["/Users/taewon/Library/Python/3.9/lib/python/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","/Users/taewon/Library/Python/3.9/lib/python/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"]},{"name":"stdout","output_type":"stream","text":["Best Hyperparameters: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 300, 'objective': 'binary:logistic', 'random_state': 0}\n","Mean F1 Score: 0.6073448494037083\n","Fold 1\n","Accuracy: 0.8493150684931506\n","Precision: 0.7692307692307693\n","Recall: 0.5555555555555556\n","F1 score: 0.6451612903225806\n","Confusion Matrix:\n","[[52  3]\n"," [ 8 10]]\n","------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["/Users/taewon/Library/Python/3.9/lib/python/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n","  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n","/var/folders/28/yz261nq91vq_lj47hynw_10r0000gn/T/ipykernel_70623/2210109296.py:35: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  predicted_classes = (probabilities[:, 1] > threshold).astype(np.int)\n","/var/folders/28/yz261nq91vq_lj47hynw_10r0000gn/T/ipykernel_70623/2210109296.py:35: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  predicted_classes = (probabilities[:, 1] > threshold).astype(np.int)\n","/var/folders/28/yz261nq91vq_lj47hynw_10r0000gn/T/ipykernel_70623/2210109296.py:35: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  predicted_classes = (probabilities[:, 1] > threshold).astype(np.int)\n"]},{"name":"stdout","output_type":"stream","text":["Fold 2\n","Accuracy: 0.7945205479452054\n","Precision: 0.5714285714285714\n","Recall: 0.6666666666666666\n","F1 score: 0.6153846153846153\n","Confusion Matrix:\n","[[46  9]\n"," [ 6 12]]\n","------------------------------\n","Fold 3\n","Accuracy: 0.7777777777777778\n","Precision: 0.6\n","Recall: 0.3333333333333333\n","F1 score: 0.42857142857142855\n","Confusion Matrix:\n","[[50  4]\n"," [12  6]]\n","------------------------------\n","Fold 4\n","Accuracy: 0.9027777777777778\n","Precision: 0.8235294117647058\n","Recall: 0.7777777777777778\n","F1 score: 0.7999999999999999\n","Confusion Matrix:\n","[[51  3]\n"," [ 4 14]]\n","------------------------------\n","Fold 5\n","Accuracy: 0.8333333333333334\n","Precision: 0.8\n","Recall: 0.4444444444444444\n","F1 score: 0.5714285714285714\n","Confusion Matrix:\n","[[52  2]\n"," [10  8]]\n","------------------------------\n","Final Test Results\n","Accuracy: 0.8055555555555556\n","Precision: 0.6363636363636364\n","Recall: 0.5185185185185185\n","F1 score: 0.5714285714285714\n","Confusion Matrix:\n","[[73  8]\n"," [13 14]]\n"]},{"name":"stderr","output_type":"stream","text":["/var/folders/28/yz261nq91vq_lj47hynw_10r0000gn/T/ipykernel_70623/2210109296.py:35: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  predicted_classes = (probabilities[:, 1] > threshold).astype(np.int)\n","/var/folders/28/yz261nq91vq_lj47hynw_10r0000gn/T/ipykernel_70623/2210109296.py:35: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  predicted_classes = (probabilities[:, 1] > threshold).astype(np.int)\n","/var/folders/28/yz261nq91vq_lj47hynw_10r0000gn/T/ipykernel_70623/2210109296.py:67: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  y_pred_final = (probabilities_final[:, 1] > threshold).astype(np.int)\n"]},{"data":{"text/plain":["([0.8493150684931506,\n","  0.7945205479452054,\n","  0.7777777777777778,\n","  0.9027777777777778,\n","  0.8333333333333334],\n"," [0.7692307692307693, 0.5714285714285714, 0.6, 0.8235294117647058, 0.8],\n"," [0.5555555555555556,\n","  0.6666666666666666,\n","  0.3333333333333333,\n","  0.7777777777777778,\n","  0.4444444444444444],\n"," [0.6451612903225806,\n","  0.6153846153846153,\n","  0.42857142857142855,\n","  0.7999999999999999,\n","  0.5714285714285714])"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["best_params, mean_f1_score = perform_xgb_grid_search(X_train, y_train, k_fold=5)\n","evaluate_xgb_with_best_params(X_train_int, y_train, X_test_int, y_test, best_params, k_fold=5)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMslPt6t0i1VXXo9sr8JOgH","gpuType":"T4","machine_shape":"hm","mount_file_id":"1530u3ee6bMgQ8qYx2NLdrQsA_-uD-nG6","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"}},"nbformat":4,"nbformat_minor":0}
