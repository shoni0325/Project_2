{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 한글 깨짐 방지\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] = 'malgun Gothic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/Users/taewon/Documents/금융 빅데이터/Project_2/코딩/상장기업/sampling data/Undersampling_0.33_train.csv', encoding='euc-kr')\n",
    "test = pd.read_csv('/Users/taewon/Documents/금융 빅데이터/Project_2/코딩/상장기업/sampling data/Undersampling_0.33_test.csv', encoding='euc-kr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[['부채비율', '자기자본순이익률', '부가가치율', '당좌자산회전률', '총자본회전률', '총자본증가율',\n",
    "       '연구개발비대비매출액', '매출액대비잉여현금흐름', '차입금의존도']]\n",
    "\n",
    "X_test = test[['부채비율', '자기자본순이익률', '부가가치율', '당좌자산회전률', '총자본회전률', '총자본증가율',\n",
    "       '연구개발비대비매출액', '매출액대비잉여현금흐름', '차입금의존도']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train[['t-1감사의견코드']]\n",
    "\n",
    "y_test = test[['t-1감사의견코드']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 서브모델 및 메타모델 설정\n",
    "submodels = [\n",
    "    RandomForestClassifier(n_estimators=100, random_state=0),\n",
    "    # LGBMClassifier(n_estimators=100, random_state=0),\n",
    "    CatBoostClassifier(iterations=100, random_state=0, verbose=0),\n",
    "    TabNetClassifier(n_d=8, n_a=8, n_steps=3, gamma=1.5, n_independent=2, n_shared=2, lambda_sparse=0.001, verbose=0)\n",
    "]\n",
    "\n",
    "meta_model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# 서브모델 및 메타모델을 활용한 스태킹 앙상블 함수\n",
    "def stacking_ensemble(submodels, meta_model, X_train, y_train, X_test, y_test, n_folds=5):\n",
    "    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=0)\n",
    "\n",
    "    meta_features_train = np.zeros((len(X_train), len(submodels)))\n",
    "    meta_features_test = np.zeros((len(X_test), len(submodels)))\n",
    "\n",
    "    for fold_idx, (train_idx, val_idx) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        X_train_fold, y_train_fold = X_train[train_idx], y_train[train_idx]\n",
    "        X_val_fold, y_val_fold = X_train[val_idx], y_train[val_idx]\n",
    "\n",
    "        for idx, model in enumerate(submodels):\n",
    "            model.fit(X_train_fold, y_train_fold)\n",
    "            val_pred = model.predict_proba(X_val_fold)[:, 1]\n",
    "            meta_features_train[val_idx, idx] = val_pred\n",
    "\n",
    "            test_pred = model.predict_proba(X_test)[:, 1]\n",
    "            meta_features_test[:, idx] += test_pred / n_folds\n",
    "\n",
    "    meta_model.fit(meta_features_train, y_train)\n",
    "    meta_pred = meta_model.predict(meta_features_test)\n",
    "\n",
    "    return meta_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Stacking Ensemble Accuracy: 0.8611111111111112\n",
      "Final Stacking Ensemble Precision: 0.8\n",
      "Final Stacking Ensemble Recall: 0.5925925925925926\n",
      "Final Stacking Ensemble F1 score: 0.6808510638297872\n",
      "Final Stacking Ensemble Confusion Matrix:\n",
      "[[77  4]\n",
      " [11 16]]\n"
     ]
    }
   ],
   "source": [
    "# 메타모델 : Logistic Regression\n",
    "# 스태킹 앙상블 수행\n",
    "meta_predictions = stacking_ensemble(submodels, meta_model, X_train.values, y_train.values.ravel(), X_test.values, y_test.values.ravel(), n_folds=5)\n",
    "\n",
    "# 최종 예측 결과 평가\n",
    "accuracy = accuracy_score(y_test.values.ravel(), meta_predictions)\n",
    "precision = precision_score(y_test.values.ravel(), meta_predictions)\n",
    "recall = recall_score(y_test.values.ravel(), meta_predictions)\n",
    "f1 = f1_score(y_test.values.ravel(), meta_predictions)\n",
    "conf_matrix = confusion_matrix(y_test.values.ravel(), meta_predictions)\n",
    "\n",
    "print(\"Final Stacking Ensemble Accuracy:\", accuracy)\n",
    "print(\"Final Stacking Ensemble Precision:\", precision)\n",
    "print(\"Final Stacking Ensemble Recall:\", recall)\n",
    "print(\"Final Stacking Ensemble F1 score:\", f1)\n",
    "print(\"Final Stacking Ensemble Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 메타모델 : LGBMClassifier\n",
    "# meta_model = LGBMClassifier()\n",
    "\n",
    "# # 스태킹 앙상블 수행\n",
    "# meta_predictions = stacking_ensemble(submodels, meta_model, X_train.values, y_train.values.ravel(), X_test.values, y_test.values.ravel(), n_folds=5)\n",
    "\n",
    "# # 최종 예측 결과 평가\n",
    "# accuracy = accuracy_score(y_test.values.ravel(), meta_predictions)\n",
    "# precision = precision_score(y_test.values.ravel(), meta_predictions)\n",
    "# recall = recall_score(y_test.values.ravel(), meta_predictions)\n",
    "# f1 = f1_score(y_test.values.ravel(), meta_predictions)\n",
    "# conf_matrix = confusion_matrix(y_test.values.ravel(), meta_predictions)\n",
    "\n",
    "# print(\"Final Stacking Ensemble Accuracy:\", accuracy)\n",
    "# print(\"Final Stacking Ensemble Precision:\", precision)\n",
    "# print(\"Final Stacking Ensemble Recall:\", recall)\n",
    "# print(\"Final Stacking Ensemble F1 score:\", f1)\n",
    "# print(\"Final Stacking Ensemble Confusion Matrix:\")\n",
    "# print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Stacking Ensemble Accuracy: 0.8333333333333334\n",
      "Final Stacking Ensemble Precision: 0.6956521739130435\n",
      "Final Stacking Ensemble Recall: 0.5925925925925926\n",
      "Final Stacking Ensemble F1 score: 0.6399999999999999\n",
      "Final Stacking Ensemble Confusion Matrix:\n",
      "[[74  7]\n",
      " [11 16]]\n"
     ]
    }
   ],
   "source": [
    "# 메타모델 : RandomForestClassifier\n",
    "meta_model = RandomForestClassifier()\n",
    "\n",
    "# 스태킹 앙상블 수행\n",
    "meta_predictions = stacking_ensemble(submodels, meta_model, X_train.values, y_train.values.ravel(), X_test.values, y_test.values.ravel(), n_folds=5)\n",
    "\n",
    "# 최종 예측 결과 평가\n",
    "accuracy = accuracy_score(y_test.values.ravel(), meta_predictions)\n",
    "precision = precision_score(y_test.values.ravel(), meta_predictions)\n",
    "recall = recall_score(y_test.values.ravel(), meta_predictions)\n",
    "f1 = f1_score(y_test.values.ravel(), meta_predictions)\n",
    "conf_matrix = confusion_matrix(y_test.values.ravel(), meta_predictions)\n",
    "\n",
    "print(\"Final Stacking Ensemble Accuracy:\", accuracy)\n",
    "print(\"Final Stacking Ensemble Precision:\", precision)\n",
    "print(\"Final Stacking Ensemble Recall:\", recall)\n",
    "print(\"Final Stacking Ensemble F1 score:\", f1)\n",
    "print(\"Final Stacking Ensemble Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Stacking Ensemble Accuracy: 0.8055555555555556\n",
      "Final Stacking Ensemble Precision: 0.6153846153846154\n",
      "Final Stacking Ensemble Recall: 0.5925925925925926\n",
      "Final Stacking Ensemble F1 score: 0.6037735849056604\n",
      "Final Stacking Ensemble Confusion Matrix:\n",
      "[[71 10]\n",
      " [11 16]]\n"
     ]
    }
   ],
   "source": [
    "# 메타모델 : XGBClassifier\n",
    "meta_model = XGBClassifier()\n",
    "\n",
    "# 스태킹 앙상블 수행\n",
    "meta_predictions = stacking_ensemble(submodels, meta_model, X_train.values, y_train.values.ravel(), X_test.values, y_test.values.ravel(), n_folds=5)\n",
    "\n",
    "# 최종 예측 결과 평가\n",
    "accuracy = accuracy_score(y_test.values.ravel(), meta_predictions)\n",
    "precision = precision_score(y_test.values.ravel(), meta_predictions)\n",
    "recall = recall_score(y_test.values.ravel(), meta_predictions)\n",
    "f1 = f1_score(y_test.values.ravel(), meta_predictions)\n",
    "conf_matrix = confusion_matrix(y_test.values.ravel(), meta_predictions)\n",
    "\n",
    "print(\"Final Stacking Ensemble Accuracy:\", accuracy)\n",
    "print(\"Final Stacking Ensemble Precision:\", precision)\n",
    "print(\"Final Stacking Ensemble Recall:\", recall)\n",
    "print(\"Final Stacking Ensemble F1 score:\", f1)\n",
    "print(\"Final Stacking Ensemble Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.0     |  0:00:00s\n",
      "epoch 1  | loss: 0.0     |  0:00:00s\n",
      "epoch 2  | loss: 0.0     |  0:00:00s\n",
      "epoch 3  | loss: 0.0     |  0:00:00s\n",
      "epoch 4  | loss: 0.0     |  0:00:00s\n",
      "epoch 5  | loss: 0.0     |  0:00:00s\n",
      "epoch 6  | loss: 0.0     |  0:00:00s\n",
      "epoch 7  | loss: 0.0     |  0:00:00s\n",
      "epoch 8  | loss: 0.0     |  0:00:00s\n",
      "epoch 9  | loss: 0.0     |  0:00:00s\n",
      "epoch 10 | loss: 0.0     |  0:00:00s\n",
      "epoch 11 | loss: 0.0     |  0:00:00s\n",
      "epoch 12 | loss: 0.0     |  0:00:00s\n",
      "epoch 13 | loss: 0.0     |  0:00:00s\n",
      "epoch 14 | loss: 0.0     |  0:00:00s\n",
      "epoch 15 | loss: 0.0     |  0:00:00s\n",
      "epoch 16 | loss: 0.0     |  0:00:00s\n",
      "epoch 17 | loss: 0.0     |  0:00:00s\n",
      "epoch 18 | loss: 0.0     |  0:00:00s\n",
      "epoch 19 | loss: 0.0     |  0:00:00s\n",
      "epoch 20 | loss: 0.0     |  0:00:00s\n",
      "epoch 21 | loss: 0.0     |  0:00:00s\n",
      "epoch 22 | loss: 0.0     |  0:00:00s\n",
      "epoch 23 | loss: 0.0     |  0:00:00s\n",
      "epoch 24 | loss: 0.0     |  0:00:00s\n",
      "epoch 25 | loss: 0.0     |  0:00:00s\n",
      "epoch 26 | loss: 0.0     |  0:00:00s\n",
      "epoch 27 | loss: 0.0     |  0:00:00s\n",
      "epoch 28 | loss: 0.0     |  0:00:00s\n",
      "epoch 29 | loss: 0.0     |  0:00:00s\n",
      "epoch 30 | loss: 0.0     |  0:00:00s\n",
      "epoch 31 | loss: 0.0     |  0:00:00s\n",
      "epoch 32 | loss: 0.0     |  0:00:00s\n",
      "epoch 33 | loss: 0.0     |  0:00:00s\n",
      "epoch 34 | loss: 0.0     |  0:00:00s\n",
      "epoch 35 | loss: 0.0     |  0:00:00s\n",
      "epoch 36 | loss: 0.0     |  0:00:00s\n",
      "epoch 37 | loss: 0.0     |  0:00:00s\n",
      "epoch 38 | loss: 0.0     |  0:00:00s\n",
      "epoch 39 | loss: 0.0     |  0:00:00s\n",
      "epoch 40 | loss: 0.0     |  0:00:00s\n",
      "epoch 41 | loss: 0.0     |  0:00:00s\n",
      "epoch 42 | loss: 0.0     |  0:00:00s\n",
      "epoch 43 | loss: 0.0     |  0:00:00s\n",
      "epoch 44 | loss: 0.0     |  0:00:00s\n",
      "epoch 45 | loss: 0.0     |  0:00:00s\n",
      "epoch 46 | loss: 0.0     |  0:00:00s\n",
      "epoch 47 | loss: 0.0     |  0:00:00s\n",
      "epoch 48 | loss: 0.0     |  0:00:00s\n",
      "epoch 49 | loss: 0.0     |  0:00:00s\n",
      "epoch 50 | loss: 0.0     |  0:00:00s\n",
      "epoch 51 | loss: 0.0     |  0:00:00s\n",
      "epoch 52 | loss: 0.0     |  0:00:00s\n",
      "epoch 53 | loss: 0.0     |  0:00:00s\n",
      "epoch 54 | loss: 0.0     |  0:00:00s\n",
      "epoch 55 | loss: 0.0     |  0:00:00s\n",
      "epoch 56 | loss: 0.0     |  0:00:00s\n",
      "epoch 57 | loss: 0.0     |  0:00:00s\n",
      "epoch 58 | loss: 0.0     |  0:00:00s\n",
      "epoch 59 | loss: 0.0     |  0:00:00s\n",
      "epoch 60 | loss: 0.0     |  0:00:00s\n",
      "epoch 61 | loss: 0.0     |  0:00:00s\n",
      "epoch 62 | loss: 0.0     |  0:00:00s\n",
      "epoch 63 | loss: 0.0     |  0:00:00s\n",
      "epoch 64 | loss: 0.0     |  0:00:00s\n",
      "epoch 65 | loss: 0.0     |  0:00:00s\n",
      "epoch 66 | loss: 0.0     |  0:00:00s\n",
      "epoch 67 | loss: 0.0     |  0:00:00s\n",
      "epoch 68 | loss: 0.0     |  0:00:00s\n",
      "epoch 69 | loss: 0.0     |  0:00:00s\n",
      "epoch 70 | loss: 0.0     |  0:00:00s\n",
      "epoch 71 | loss: 0.0     |  0:00:00s\n",
      "epoch 72 | loss: 0.0     |  0:00:00s\n",
      "epoch 73 | loss: 0.0     |  0:00:00s\n",
      "epoch 74 | loss: 0.0     |  0:00:00s\n",
      "epoch 75 | loss: 0.0     |  0:00:00s\n",
      "epoch 76 | loss: 0.0     |  0:00:00s\n",
      "epoch 77 | loss: 0.0     |  0:00:00s\n",
      "epoch 78 | loss: 0.0     |  0:00:00s\n",
      "epoch 79 | loss: 0.0     |  0:00:00s\n",
      "epoch 80 | loss: 0.0     |  0:00:00s\n",
      "epoch 81 | loss: 0.0     |  0:00:00s\n",
      "epoch 82 | loss: 0.0     |  0:00:00s\n",
      "epoch 83 | loss: 0.0     |  0:00:00s\n",
      "epoch 84 | loss: 0.0     |  0:00:00s\n",
      "epoch 85 | loss: 0.0     |  0:00:00s\n",
      "epoch 86 | loss: 0.0     |  0:00:00s\n",
      "epoch 87 | loss: 0.0     |  0:00:00s\n",
      "epoch 88 | loss: 0.0     |  0:00:00s\n",
      "epoch 89 | loss: 0.0     |  0:00:00s\n",
      "epoch 90 | loss: 0.0     |  0:00:00s\n",
      "epoch 91 | loss: 0.0     |  0:00:00s\n",
      "epoch 92 | loss: 0.0     |  0:00:00s\n",
      "epoch 93 | loss: 0.0     |  0:00:00s\n",
      "epoch 94 | loss: 0.0     |  0:00:00s\n",
      "epoch 95 | loss: 0.0     |  0:00:00s\n",
      "epoch 96 | loss: 0.0     |  0:00:00s\n",
      "epoch 97 | loss: 0.0     |  0:00:00s\n",
      "epoch 98 | loss: 0.0     |  0:00:00s\n",
      "epoch 99 | loss: 0.0     |  0:00:00s\n",
      "Final Stacking Ensemble Accuracy: 0.6574074074074074\n",
      "Final Stacking Ensemble Precision: 0.0\n",
      "Final Stacking Ensemble Recall: 0.0\n",
      "Final Stacking Ensemble F1 score: 0.0\n",
      "Final Stacking Ensemble Confusion Matrix:\n",
      "[[71 10]\n",
      " [27  0]]\n"
     ]
    }
   ],
   "source": [
    "# 메타모델 : TabNetClassifier\n",
    "meta_model = TabNetClassifier()\n",
    "\n",
    "# 스태킹 앙상블 수행\n",
    "meta_predictions = stacking_ensemble(submodels, meta_model, X_train.values, y_train.values.ravel(), X_test.values, y_test.values.ravel(), n_folds=5)\n",
    "\n",
    "# 최종 예측 결과 평가\n",
    "accuracy = accuracy_score(y_test.values.ravel(), meta_predictions)\n",
    "precision = precision_score(y_test.values.ravel(), meta_predictions)\n",
    "recall = recall_score(y_test.values.ravel(), meta_predictions)\n",
    "f1 = f1_score(y_test.values.ravel(), meta_predictions)\n",
    "conf_matrix = confusion_matrix(y_test.values.ravel(), meta_predictions)\n",
    "\n",
    "print(\"Final Stacking Ensemble Accuracy:\", accuracy)\n",
    "print(\"Final Stacking Ensemble Precision:\", precision)\n",
    "print(\"Final Stacking Ensemble Recall:\", recall)\n",
    "print(\"Final Stacking Ensemble F1 score:\", f1)\n",
    "print(\"Final Stacking Ensemble Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Stacking Ensemble Accuracy: 0.8518518518518519\n",
    "# Final Stacking Ensemble Precision: 0.7037037037037037\n",
    "# Final Stacking Ensemble Recall: 0.7037037037037037\n",
    "# Final Stacking Ensemble F1 score: 0.7037037037037037\n",
    "# Final Stacking Ensemble Confusion Matrix:\n",
    "# [[73  8]\n",
    "#  [ 8 19]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
